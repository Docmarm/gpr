import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
from datetime import datetime, timedelta
import io
import os
from typing import Dict, List, Tuple, Optional, Any

# ---------------------------------------------------------------------
# Constantes et Utilitaires
# ---------------------------------------------------------------------
EXCEL_MIME_TYPE = "application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
DATE_FORMAT = '%Y-%m-%d'

# --- Valeurs par d√©faut pour les param√®tres (seront stock√©es dans session_state) ---
DEFAULT_SEUIL_HEURES_RAPPROCHEES = 2
DEFAULT_CONSO_SEUIL = 16.0
DEFAULT_HEURE_DEBUT_NON_OUVRE = 20
DEFAULT_HEURE_FIN_NON_OUVRE = 6
DEFAULT_DELTA_MINUTES_FACTURATION_DOUBLE = 60
DEFAULT_SEUIL_ANOMALIES_SUSPECTES_SCORE = 10 # Bas√© sur un score pond√©r√©

# --- Poids par d√©faut pour le score de risque ---
DEFAULT_POIDS_CONSO_EXCESSIVE = 5
DEFAULT_POIDS_DEPASSEMENT_CAPACITE = 10
DEFAULT_POIDS_PRISES_RAPPROCHEES = 3
DEFAULT_POIDS_KM_DECROISSANT = 8
DEFAULT_POIDS_KM_INCHANGE = 2
DEFAULT_POIDS_KM_SAUT = 6
DEFAULT_POIDS_HORS_HORAIRE = 2
DEFAULT_POIDS_HORS_SERVICE = 9
DEFAULT_POIDS_FACT_DOUBLE = 7

# ---------------------------------------------------------------------
# Initialisation Session State pour les Param√®tres
# ---------------------------------------------------------------------
def initialize_session_state(df_vehicules: Optional[pd.DataFrame] = None):
    """Initialise les param√®tres dans st.session_state s'ils n'existent pas."""
    defaults = {
        'ss_seuil_heures_rapprochees': DEFAULT_SEUIL_HEURES_RAPPROCHEES,
        'ss_heure_debut_non_ouvre': DEFAULT_HEURE_DEBUT_NON_OUVRE,
        'ss_heure_fin_non_ouvre': DEFAULT_HEURE_FIN_NON_OUVRE,
        'ss_delta_minutes_facturation_double': DEFAULT_DELTA_MINUTES_FACTURATION_DOUBLE,
        'ss_seuil_anomalies_suspectes_score': DEFAULT_SEUIL_ANOMALIES_SUSPECTES_SCORE,
        'ss_poids_conso_excessive': DEFAULT_POIDS_CONSO_EXCESSIVE,
        'ss_poids_depassement_capacite': DEFAULT_POIDS_DEPASSEMENT_CAPACITE,
        'ss_poids_prises_rapprochees': DEFAULT_POIDS_PRISES_RAPPROCHEES,
        'ss_poids_km_decroissant': DEFAULT_POIDS_KM_DECROISSANT,
        'ss_poids_km_inchange': DEFAULT_POIDS_KM_INCHANGE,
        'ss_poids_km_saut': DEFAULT_POIDS_KM_SAUT,
        'ss_poids_hors_horaire': DEFAULT_POIDS_HORS_HORAIRE,
        'ss_poids_hors_service': DEFAULT_POIDS_HORS_SERVICE,
        'ss_poids_fact_double': DEFAULT_POIDS_FACT_DOUBLE,
        'ss_conso_seuils_par_categorie': {}, # Sera peupl√© dynamiquement
        'data_loaded': False # Indicateur de chargement des donn√©es
    }
    for key, value in defaults.items():
        if key not in st.session_state:
            st.session_state[key] = value

    # Initialisation dynamique des seuils de conso par cat√©gorie
    if df_vehicules is not None and not st.session_state['ss_conso_seuils_par_categorie']:
        all_cats = sorted(df_vehicules['Cat√©gorie'].dropna().astype(str).unique())
        st.session_state['ss_conso_seuils_par_categorie'] = {cat: DEFAULT_CONSO_SEUIL for cat in all_cats}
    elif df_vehicules is not None:
        # S'assurer que toutes les cat√©gories actuelles ont un seuil
        all_cats = sorted(df_vehicules['Cat√©gorie'].dropna().astype(str).unique())
        current_seuils = st.session_state['ss_conso_seuils_par_categorie']
        updated_seuils = {cat: current_seuils.get(cat, DEFAULT_CONSO_SEUIL) for cat in all_cats}
        st.session_state['ss_conso_seuils_par_categorie'] = updated_seuils


# ---------------------------------------------------------------------
# Fonctions : Nettoyage et chargement (inchang√©es sauf ajout Type Hints)
# ---------------------------------------------------------------------
def nettoyer_numero_carte(numero: Any) -> str:
    """Convertit un num√©ro de carte en entier si possible, puis string, retirant les espaces."""
    if pd.isna(numero):
        return ""
    try:
        # Tenter conversion en float puis int pour g√©rer les ".0" puis en str
        return str(int(float(str(numero)))).strip()
    except ValueError:
         # Si la conversion √©choue, retourner le num√©ro comme string nettoy√©
        return str(numero).strip()
    except Exception:
        # Fallback g√©n√©ral
        return str(numero).strip()

@st.cache_data(show_spinner="Chargement et nettoyage des fichiers...")
def charger_donnees(fichier_transactions, fichier_cartes) -> Tuple[Optional[pd.DataFrame], Optional[pd.DataFrame], Optional[pd.DataFrame], Optional[pd.DataFrame]]:
    """Charge et nettoie les donn√©es des fichiers CSV et Excel."""
    df_transactions, df_vehicules, df_ge, df_autres = None, None, None, None

    # --- Chargement Transactions ---
    try:
        df_transactions = pd.read_csv(fichier_transactions, sep=';', encoding='utf-8', low_memory=False)
        # Renommage potentiel si la colonne Amount s'appelle 'Amount eur'
        if 'Amount eur' in df_transactions.columns and 'Amount' not in df_transactions.columns:
             df_transactions.rename(columns={'Amount eur': 'Amount'}, inplace=True)
        if 'Place' not in df_transactions.columns and 'Place name' in df_transactions.columns:
             df_transactions.rename(columns={'Place name': 'Place'}, inplace=True)

    except Exception as e:
        st.error(f"Erreur lors de la lecture du fichier de transactions : {e}")
        return None, None, None, None

    # --- Chargement Cartes ---
    try:
        xls = pd.ExcelFile(fichier_cartes)
        required_sheets = {'CARTES VEHICULE', 'CARTES GE', 'AUTRES CARTES'}
        available_sheets = set(xls.sheet_names)
        if not required_sheets.issubset(available_sheets):
             st.error(f"Feuilles manquantes dans le fichier Excel. Attendues: {required_sheets}. Trouv√©es: {available_sheets}")
             return None, None, None, None

        df_vehicules = pd.read_excel(xls, sheet_name='CARTES VEHICULE')
        df_ge = pd.read_excel(xls, sheet_name='CARTES GE')
        df_autres = pd.read_excel(xls, sheet_name='AUTRES CARTES')
    except Exception as e:
        st.error(f"Erreur lors de la lecture du fichier des cartes : {e}")
        return None, None, None, None

    # --- V√©rification Colonnes Transactions ---
    colonnes_attendues_transactions = ['Date', 'Hour', 'Card num.', 'Quantity', 'Past mileage', 'Current mileage', 'Amount', 'Place']
    missing_cols_trans = [col for col in colonnes_attendues_transactions if col not in df_transactions.columns]
    if missing_cols_trans:
        st.error(f"Colonnes manquantes dans le fichier de transactions: {', '.join(missing_cols_trans)}")
        return None, None, None, None

    # --- V√©rification Colonnes Cartes ---
    colonnes_attendues_cartes = ['N¬∞ Carte']
    dfs_cartes = {'CARTES VEHICULE': df_vehicules, 'CARTES GE': df_ge, 'AUTRES CARTES': df_autres}
    for nom_feuille, df_sheet in dfs_cartes.items():
        missing_cols_carte = [col for col in colonnes_attendues_cartes if col not in df_sheet.columns]
        if missing_cols_carte:
            st.error(f"Colonne(s) manquante(s) dans la feuille '{nom_feuille}': {', '.join(missing_cols_carte)}")
            return None, None, None, None
        # V√©rifier et convertir 'Cap-r√®servoir' si existe
        if 'Cap-r√®servoir' in df_sheet.columns:
            df_sheet['Cap-r√®servoir'] = pd.to_numeric(df_sheet['Cap-r√®servoir'], errors='coerce').fillna(0)
        # Assurer que Cat√©gorie est string
        if 'Cat√©gorie' in df_sheet.columns:
            df_sheet['Cat√©gorie'] = df_sheet['Cat√©gorie'].astype(str).fillna('Non d√©fini')


    # --- Nettoyage Num√©ros de Carte ---
    df_transactions['Card num.'] = df_transactions['Card num.'].apply(nettoyer_numero_carte)
    for df_sheet in [df_vehicules, df_ge, df_autres]:
        df_sheet['N¬∞ Carte'] = df_sheet['N¬∞ Carte'].apply(nettoyer_numero_carte)
        df_sheet.dropna(subset=['N¬∞ Carte'], inplace=True) # Supprimer lignes sans N¬∞ Carte
        df_sheet = df_sheet[df_sheet['N¬∞ Carte'] != ""]

    # --- Conversion Types Transactions ---
    df_transactions['Date'] = pd.to_datetime(df_transactions['Date'], format='%d/%m/%Y', errors='coerce')
    # Gestion flexible du format horaire
    try:
        df_transactions['Hour'] = pd.to_datetime(df_transactions['Hour'], format='%H:%M:%S', errors='coerce').dt.time
    except ValueError:
        try:
            # Essayer un autre format si le premier √©choue
             df_transactions['Hour'] = pd.to_datetime(df_transactions['Hour'], format='%H:%M', errors='coerce').dt.time
        except Exception as e:
             st.warning(f"Impossible de parser la colonne 'Hour'. V√©rifiez le format (HH:MM:SS ou HH:MM). Erreur: {e}")
             # Mettre NaN si le parsing √©choue
             df_transactions['Hour'] = pd.NaT

    for col in ['Quantity', 'Past mileage', 'Current mileage', 'Amount']:
        df_transactions[col] = pd.to_numeric(df_transactions[col].astype(str).str.replace(',', '.'), errors='coerce') # Remplacer virgule par point pour d√©cimales

    # --- Suppression Lignes Invalides ---
    df_transactions.dropna(subset=['Date', 'Card num.'], inplace=True)
    df_transactions = df_transactions[df_transactions['Card num.'] != ""]
    # Recr√©er les df cartes apr√®s nettoyage potentiellement plus strict
    df_vehicules = df_vehicules[df_vehicules['N¬∞ Carte'] != ""]
    df_ge = df_ge[df_ge['N¬∞ Carte'] != ""]
    df_autres = df_autres[df_autres['N¬∞ Carte'] != ""]

    # Ajouter colonne DateTime pour faciliter tris et calculs de delta
    df_transactions['DateTime'] = df_transactions.apply(
        lambda row: datetime.combine(row['Date'].date(), row['Hour']) if pd.notna(row['Date']) and pd.notna(row['Hour']) else pd.NaT,
        axis=1
    )
    df_transactions.dropna(subset=['DateTime'], inplace=True) # Important pour les analyses temporelles

    return df_transactions, df_vehicules, df_ge, df_autres

# ---------------------------------------------------------------------
# Fonctions : export Excel + affichage DataFrame (inchang√©es)
# ---------------------------------------------------------------------
def to_excel(df: pd.DataFrame) -> bytes:
    """Convertit un DataFrame en un fichier Excel (BytesIO)."""
    output = io.BytesIO()
    with pd.ExcelWriter(output, engine='openpyxl') as writer:
        # Copier pour √©viter SettingWithCopyWarning lors du formatage
        df_copy = df.copy()
        # Formater les colonnes de date si elles existent et sont de type datetime
        for col in df_copy.select_dtypes(include=['datetime64[ns]']).columns:
             df_copy[col] = df_copy[col].dt.strftime(DATE_FORMAT)
        df_copy.to_excel(writer, index=False, sheet_name='Sheet1')
    return output.getvalue()

def afficher_dataframe_avec_export(df: pd.DataFrame, titre: str = "Tableau", key: str = "df"):
    """Affiche un DataFrame + un bouton d'export Excel."""
    if df is None or df.empty:
        st.info(f"{titre} : Aucune donn√©e √† afficher.")
        return

    nb_lignes = len(df)
    st.markdown(f"### {titre} ({nb_lignes:,} lignes)")

    # Affichage avec gestion de la largeur dynamique
    st.dataframe(df, use_container_width=True)

    try:
        excel_data = to_excel(df)
        nom_fic = f"{titre.lower().replace(' ', '_').replace('(', '').replace(')', '').replace(':', '')[:50]}.xlsx" # Nettoyage nom fichier
        st.download_button(
            label=f"Exporter '{titre}' en Excel",
            data=excel_data,
            file_name=nom_fic,
            mime=EXCEL_MIME_TYPE,
            key=f"export_{key}"
        )
    except Exception as e:
        st.error(f"Erreur lors de la g√©n√©ration de l'export Excel pour '{titre}': {e}")


# ---------------------------------------------------------------------
# Fonctions : V√©rifications et Analyses (Mises √† jour pour utiliser session_state)
# ---------------------------------------------------------------------

def verifier_cartes_inconnues(df_transactions: pd.DataFrame, df_vehicules: pd.DataFrame, df_ge: pd.DataFrame, df_autres: pd.DataFrame) -> pd.DataFrame:
    """Identifie les transactions associ√©es √† des cartes non list√©es."""
    cartes_vehicules = set(df_vehicules['N¬∞ Carte'].unique()) if df_vehicules is not None else set()
    cartes_ge = set(df_ge['N¬∞ Carte'].unique()) if df_ge is not None else set()
    cartes_autres = set(df_autres['N¬∞ Carte'].unique()) if df_autres is not None else set()
    cartes_valides = cartes_vehicules.union(cartes_ge).union(cartes_autres)

    cartes_utilisees = set(df_transactions['Card num.'].unique())
    cartes_inconnues = cartes_utilisees - cartes_valides

    if not cartes_inconnues:
        return pd.DataFrame() # Retourner un DF vide si aucune carte inconnue

    df_inc = df_transactions[df_transactions['Card num.'].isin(cartes_inconnues)].copy()

    # Essayer de r√©cup√©rer le nom de la carte depuis les transactions
    if 'Card name' in df_inc.columns:
        stats = df_inc.groupby(['Card num.', 'Card name']).agg(
            Nombre_transactions=('Quantity', 'count'),
            Volume_total_L=('Quantity', 'sum'),
            Montant_total_CFA=('Amount', 'sum')
        ).round(2).reset_index()
    else:
         stats = df_inc.groupby('Card num.').agg(
            Nombre_transactions=('Quantity', 'count'),
            Volume_total_L=('Quantity', 'sum'),
            Montant_total_CFA=('Amount', 'sum')
        ).round(2).reset_index()
         stats['Card name'] = 'Nom non disponible' # Ajouter colonne si absente

    # R√©organiser colonnes
    stats = stats[['Card num.', 'Card name', 'Nombre_transactions', 'Volume_total_L', 'Montant_total_CFA']]
    return stats

# --- D√©tection des anomalies ---

def detecter_anomalies(
    df_transactions: pd.DataFrame,
    df_vehicules: pd.DataFrame
) -> pd.DataFrame:
    """
    Fonction centrale (simplifi√©e) pour d√©tecter toutes les anomalies sur les v√©hicules.
    Retourne un DataFrame unique avec toutes les anomalies d√©tect√©es.
    """
    all_anomalies = []
    df_merged = df_transactions.merge(
        df_vehicules[['N¬∞ Carte', 'Nouveau Immat', 'Cat√©gorie', 'Type', 'Cap-r√®servoir']],
        left_on='Card num.',
        right_on='N¬∞ Carte',
        how='inner' # Garder seulement les transactions des cartes v√©hicules connues
    )
    df_merged['distance_parcourue'] = df_merged['Current mileage'] - df_merged['Past mileage']
    df_merged['consommation_100km'] = np.where(
         (df_merged['distance_parcourue'] > 0) & df_merged['Quantity'].notna(),
         (df_merged['Quantity'] / df_merged['distance_parcourue']) * 100,
         np.nan
    )

    # R√©cup√©rer les param√®tres depuis session_state
    seuils_conso = st.session_state.get('ss_conso_seuils_par_categorie', {})
    seuil_heures_rapprochees = st.session_state.get('ss_seuil_heures_rapprochees', DEFAULT_SEUIL_HEURES_RAPPROCHEES)
    heure_debut_non_ouvre = st.session_state.get('ss_heure_debut_non_ouvre', DEFAULT_HEURE_DEBUT_NON_OUVRE)
    heure_fin_non_ouvre = st.session_state.get('ss_heure_fin_non_ouvre', DEFAULT_HEURE_FIN_NON_OUVRE)
    delta_minutes_double = st.session_state.get('ss_delta_minutes_facturation_double', DEFAULT_DELTA_MINUTES_FACTURATION_DOUBLE)

    # --- 1. Consommation Excessive ---
    for index, row in df_merged.iterrows():
        cat = row['Cat√©gorie']
        seuil = seuils_conso.get(cat, DEFAULT_CONSO_SEUIL) # Utiliser seuil sp√©cifique ou d√©faut
        if pd.notna(row['consommation_100km']) and row['consommation_100km'] > seuil:
            anomalie = row.to_dict()
            anomalie['type_anomalie'] = 'Consommation excessive'
            anomalie['detail_anomalie'] = f"{row['consommation_100km']:.1f} L/100km > seuil {seuil} L/100km"
            anomalie['poids_anomalie'] = st.session_state.get('ss_poids_conso_excessive', DEFAULT_POIDS_CONSO_EXCESSIVE)
            all_anomalies.append(anomalie)

    # --- 2. D√©passement Capacit√© ---
    depassement = df_merged[df_merged['Quantity'] > df_merged['Cap-r√®servoir']].copy()
    if not depassement.empty:
         depassement['type_anomalie'] = 'D√©passement capacit√©'
         depassement['detail_anomalie'] = depassement.apply(lambda x: f"Volume: {x['Quantity']:.1f}L > Capacit√©: {x['Cap-r√®servoir']:.1f}L", axis=1)
         depassement['poids_anomalie'] = st.session_state.get('ss_poids_depassement_capacite', DEFAULT_POIDS_DEPASSEMENT_CAPACITE)
         all_anomalies.extend(depassement.to_dict('records'))

    # --- 3. Prises Rapproch√©es ---
    df_merged_sorted = df_merged.sort_values(['Card num.', 'DateTime'])
    rapprochees_indices = set()
    for carte in df_merged_sorted['Card num.'].unique():
        sub = df_merged_sorted[df_merged_sorted['Card num.'] == carte]
        if len(sub) > 1:
            time_diff = sub['DateTime'].diff().dt.total_seconds() / 3600 # Diff√©rence en heures
            # Identifier les indices o√π la diff√©rence est inf√©rieure au seuil
            indices_anomalie = sub.index[time_diff < seuil_heures_rapprochees]
            # Ajouter l'indice pr√©c√©dent aussi pour avoir la paire
            indices_precedents = sub.index[time_diff.shift(-1) < seuil_heures_rapprochees]
            rapprochees_indices.update(indices_anomalie)
            rapprochees_indices.update(indices_precedents)

    if rapprochees_indices:
        rapprochees_df = df_merged_sorted.loc[list(rapprochees_indices)].copy()
        rapprochees_df['type_anomalie'] = 'Prises rapproch√©es'
        rapprochees_df['detail_anomalie'] = f'Moins de {seuil_heures_rapprochees}h entre prises'
        rapprochees_df['poids_anomalie'] = st.session_state.get('ss_poids_prises_rapprochees', DEFAULT_POIDS_PRISES_RAPPROCHEES)
        all_anomalies.extend(rapprochees_df.to_dict('records'))


    # --- 4. Anomalies Kilom√©trage ---
    km_anomalies = []
    for carte in df_merged_sorted['Card num.'].unique():
        df_carte = df_merged_sorted[df_merged_sorted['Card num.'] == carte]
        prev_m = None
        prev_row = None
        for index, row in df_carte.iterrows():
            curr_m = row['Current mileage']
            past_m = row['Past mileage'] # Kilom√©trage pr√©c√©dent de la transaction
            user = row.get('Card name', 'N/A')

            # V√©rif Valeur manquante ou nulle
            if pd.isna(curr_m) or curr_m == 0 or pd.isna(past_m) :
                 # On pourrait ajouter une anomalie ici si d√©sir√©
                 prev_m = None # R√©initialiser si km manquant
                 prev_row = row
                 continue

            # V√©rif coh√©rence Past vs Current de la m√™me ligne
            if past_m > curr_m:
                 anomalie = row.to_dict()
                 anomalie['type_anomalie'] = 'Kilom√©trage incoh√©rent (transaction)'
                 anomalie['detail_anomalie'] = f"Km d√©but ({past_m}) > Km fin ({curr_m})"
                 anomalie['poids_anomalie'] = st.session_state.get('ss_poids_km_decroissant', DEFAULT_POIDS_KM_DECROISSANT) # Poids √©lev√©
                 km_anomalies.append(anomalie)
                 # Ne pas utiliser cette valeur pour la comparaison suivante si incoh√©rente
                 prev_m = None
                 prev_row = row
                 continue

            if prev_m is not None and prev_row is not None:
                 # V√©rif D√©croissant entre transactions
                 if curr_m < prev_m:
                     anomalie = row.to_dict()
                     anomalie['type_anomalie'] = 'Kilom√©trage d√©croissant (inter-transactions)'
                     anomalie['detail_anomalie'] = f"Km transaction N ({curr_m}) < Km transaction N-1 ({prev_m})"
                     anomalie['poids_anomalie'] = st.session_state.get('ss_poids_km_decroissant', DEFAULT_POIDS_KM_DECROISSANT)
                     km_anomalies.append(anomalie)
                 # V√©rif Inchang√© entre transactions
                 elif curr_m == prev_m:
                     anomalie = row.to_dict()
                     anomalie['type_anomalie'] = 'Kilom√©trage inchang√© (inter-transactions)'
                     anomalie['detail_anomalie'] = f"Km identique √† la transaction pr√©c√©dente: {curr_m} km"
                     anomalie['poids_anomalie'] = st.session_state.get('ss_poids_km_inchange', DEFAULT_POIDS_KM_INCHANGE)
                     km_anomalies.append(anomalie)
                 # V√©rif Saut Anormal
                 elif (curr_m - prev_m) > 1000: # Seuil de saut √† param√©trer potentiellement
                     anomalie = row.to_dict()
                     anomalie['type_anomalie'] = 'Saut kilom√©trage important'
                     anomalie['detail_anomalie'] = f"Augmentation de +{curr_m - prev_m} km depuis transaction pr√©c√©dente"
                     anomalie['poids_anomalie'] = st.session_state.get('ss_poids_km_saut', DEFAULT_POIDS_KM_SAUT)
                     km_anomalies.append(anomalie)
            prev_m = curr_m
            prev_row = row
    all_anomalies.extend(km_anomalies)


    # --- 5. Transactions Hors Horaires / Weekend ---
    df_merged['heure'] = df_merged['DateTime'].dt.hour
    df_merged['jour_semaine'] = df_merged['DateTime'].dt.dayofweek # Lundi=0, Dimanche=6

    # Condition pour heures non ouvr√©es (g√®re le cas o√π l'intervalle passe minuit)
    if heure_debut_non_ouvre < heure_fin_non_ouvre: # Ex: 8h -> 18h (journ√©e) => NON OUVRE = <8 ou >18
        cond_heure = (df_merged['heure'] < heure_fin_non_ouvre) | (df_merged['heure'] >= heure_debut_non_ouvre)
    else: # Ex: 20h -> 6h (nuit) => NON OUVRE = >=20 ou <6
        cond_heure = (df_merged['heure'] >= heure_debut_non_ouvre) | (df_merged['heure'] < heure_fin_non_ouvre)

    cond_weekend = (df_merged['jour_semaine'] >= 5) # Samedi ou Dimanche

    anomalies_hor = df_merged[cond_heure | cond_weekend].copy()
    if not anomalies_hor.empty:
        anomalies_hor['type_anomalie'] = 'Hors Horaires / Weekend'
        anomalies_hor['detail_anomalie'] = anomalies_hor.apply(
            lambda r: f"{r['DateTime'].strftime('%A %H:%M')} " + \
                      ("(Weekend)" if r['jour_semaine'] >= 5 else "") + \
                      ("(Heures non ouvr√©es)" if (cond_heure.loc[r.name]) else ""), # Utiliser .loc pour acc√©der √† la condition bool√©enne par index
            axis=1
        )
        anomalies_hor['poids_anomalie'] = st.session_state.get('ss_poids_hors_horaire', DEFAULT_POIDS_HORS_HORAIRE)
        all_anomalies.extend(anomalies_hor.to_dict('records'))

    # --- 6. Transactions V√©hicules Hors Service ---
    hors_service = df_merged[df_merged['Type'].isin(['EN PANNE', 'IMMO'])].copy()
    if not hors_service.empty:
        hors_service['type_anomalie'] = 'V√©hicule Hors Service'
        hors_service['detail_anomalie'] = 'Transaction alors que v√©hicule EN PANNE ou IMMO'
        hors_service['poids_anomalie'] = st.session_state.get('ss_poids_hors_service', DEFAULT_POIDS_HORS_SERVICE)
        all_anomalies.extend(hors_service.to_dict('records'))

    # --- 7. Facturation Double ---
    double_indices = set()
    for carte in df_merged_sorted['Card num.'].unique():
        sub = df_merged_sorted[df_merged_sorted['Card num.'] == carte]
        if len(sub) > 1:
            for i in range(len(sub) - 1):
                rowA = sub.iloc[i]
                rowB = sub.iloc[i+1]
                delta_sec = (rowB['DateTime'] - rowA['DateTime']).total_seconds()
                if delta_sec >= 0 and (delta_sec / 60.0) < delta_minutes_double and rowA['Amount'] == rowB['Amount'] and pd.notna(rowA['Amount']):
                    double_indices.add(sub.index[i])
                    double_indices.add(sub.index[i+1])

    if double_indices:
        doubles_df = df_merged_sorted.loc[list(double_indices)].copy()
        doubles_df['type_anomalie'] = 'Facturation double suspect√©e'
        doubles_df['detail_anomalie'] = f"Montant identique ({doubles_df['Amount']}) en < {delta_minutes_double} min"
        doubles_df['poids_anomalie'] = st.session_state.get('ss_poids_fact_double', DEFAULT_POIDS_FACT_DOUBLE)
        all_anomalies.extend(doubles_df.to_dict('records'))

    # --- Finalisation ---
    if not all_anomalies:
        return pd.DataFrame()

    df_final_anomalies = pd.DataFrame(all_anomalies)

    # S√©lection et renommage des colonnes pertinentes
    cols_to_keep = [
        'Date', 'Hour', 'DateTime', 'Card num.', 'Nouveau Immat', 'Cat√©gorie', 'Type',
        'Quantity', 'Amount', 'Past mileage', 'Current mileage', 'distance_parcourue',
        'consommation_100km', 'Cap-r√®servoir', 'Place', 'Card name',
        'type_anomalie', 'detail_anomalie', 'poids_anomalie'
    ]
    # Garder seulement les colonnes existantes pour √©viter les erreurs
    cols_final = [col for col in cols_to_keep if col in df_final_anomalies.columns]
    df_final_anomalies = df_final_anomalies[cols_final]

    # Supprimer les doublons exacts (une m√™me transaction peut d√©clencher plusieurs types d'anomalies, ex: conso excessive ET hors horaire)
    # On garde ici les doublons si une transaction a plusieurs anomalies, l'agr√©gation en tiendra compte
    # df_final_anomalies = df_final_anomalies.drop_duplicates(subset=['DateTime', 'Card num.', 'type_anomalie']) # Optionnel: d√©doublonner par type

    return df_final_anomalies.sort_values(by=['Nouveau Immat', 'DateTime', 'type_anomalie'])


# --- Fonctions d'analyse sp√©cifiques ---

def analyser_consommation_vehicule(vehicule_data: pd.DataFrame, info_vehicule: pd.Series) -> Dict[str, Any]:
    """Analyse la consommation d'un v√©hicule sp√©cifique."""
    if vehicule_data.empty:
        return {
            'total_litres': 0, 'nb_prises': 0, 'moyenne_prise': 0,
            'distance_totale': 0, 'consommation_moyenne': 0,
            'cout_total': 0, 'cout_moyen_prise': 0, 'cout_par_km': 0,
            'conso_mensuelle': pd.DataFrame(), 'stations_frequentes': pd.Series(dtype='int64'),
            'prix_moyen_litre': 0
        }

    vehicule_data_sorted = vehicule_data.sort_values('DateTime')
    total_litres = vehicule_data_sorted['Quantity'].sum()
    cout_total = vehicule_data_sorted['Amount'].sum()
    nb_prises = len(vehicule_data_sorted)
    moyenne_prise = vehicule_data_sorted['Quantity'].mean() if nb_prises > 0 else 0
    cout_moyen_prise = vehicule_data_sorted['Amount'].mean() if nb_prises > 0 else 0
    prix_moyen_litre = (cout_total / total_litres) if total_litres > 0 else 0

    # Calcul de la distance et consommation moyenne (plus robuste)
    df_km = vehicule_data_sorted[['Past mileage', 'Current mileage']].dropna()
    distance_totale = 0
    consommation_moyenne = 0
    cout_par_km = 0

    if not df_km.empty and len(df_km) > 1:
        # Utiliser la diff√©rence entre le tout premier 'Past mileage' et le tout dernier 'Current mileage'
        first_km = df_km['Past mileage'].iloc[0]
        last_km = df_km['Current mileage'].iloc[-1]
        if pd.notna(first_km) and pd.notna(last_km) and last_km > first_km:
            distance_totale = last_km - first_km

    # Alternative: sommer les distances de chaque transaction valide
    vehicule_data_sorted['distance_transaction'] = vehicule_data_sorted['Current mileage'] - vehicule_data_sorted['Past mileage']
    distance_sommee_valide = vehicule_data_sorted.loc[vehicule_data_sorted['distance_transaction'] > 0, 'distance_transaction'].sum()
    # Choisir la m√©thode de calcul de distance (ici on prend la somme des transactions valides si > 0)
    if distance_sommee_valide > 0:
        distance_utilisee = distance_sommee_valide
        consommation_moyenne = (total_litres / distance_utilisee) * 100 if distance_utilisee > 0 else 0
        cout_par_km = (cout_total / distance_utilisee) if distance_utilisee > 0 else 0
    elif distance_totale > 0: # Fallback sur first/last
        distance_utilisee = distance_totale
        consommation_moyenne = (total_litres / distance_utilisee) * 100 if distance_utilisee > 0 else 0
        cout_par_km = (cout_total / distance_utilisee) if distance_utilisee > 0 else 0
    else:
        distance_utilisee = 0


    vehicule_data_sorted['mois'] = vehicule_data_sorted['Date'].dt.strftime('%Y-%m')
    conso_mensuelle = vehicule_data_sorted.groupby('mois').agg(
        Volume_L=('Quantity', 'sum'),
        Montant_CFA=('Amount','sum'),
        Nb_prises=('Quantity', 'count'),
        Volume_moyen_L=('Quantity', 'mean')
    )
    stations_freq = vehicule_data_sorted['Place'].value_counts().head(5)

    return {
        'total_litres': total_litres,
        'nb_prises': nb_prises,
        'moyenne_prise': moyenne_prise,
        'distance_totale_estimee': distance_utilisee, # Renomm√© pour clart√©
        'consommation_moyenne': consommation_moyenne,
        'cout_total': cout_total,
        'cout_moyen_prise': cout_moyen_prise,
        'cout_par_km': cout_par_km,
        'conso_mensuelle': conso_mensuelle,
        'stations_frequentes': stations_freq,
        'prix_moyen_litre': prix_moyen_litre
    }

def generer_rapport_vehicule(donnees_vehicule: pd.DataFrame, info_vehicule: pd.Series, date_debut: datetime.date, date_fin: datetime.date, conso_moyenne_categorie: float) -> Tuple[pd.DataFrame, pd.DataFrame, pd.DataFrame, pd.Series, Dict[str, Any]]:
    """G√©n√®re un rapport d√©taill√© pour un v√©hicule, incluant le benchmarking."""
    infos_base = pd.DataFrame({
        'Param√®tre': ['Immatriculation', 'Marque', 'Mod√®le', 'Type', 'Cat√©gorie', 'Capacit√© r√©servoir', 'P√©riode d√©but', 'P√©riode fin'],
        'Valeur': [
            info_vehicule.get('Nouveau Immat', 'N/A'), info_vehicule.get('Marque', 'N/A'), info_vehicule.get('Mod√®le', 'N/A'),
            info_vehicule.get('Type', 'N/A'), info_vehicule.get('Cat√©gorie', 'N/A'), f"{info_vehicule.get('Cap-r√®servoir', 0):.0f} L",
            date_debut.strftime(DATE_FORMAT), date_fin.strftime(DATE_FORMAT)
        ]
    })

    analyse = analyser_consommation_vehicule(donnees_vehicule, info_vehicule)

    # Comparaison Benchmarking
    conso_veh = analyse['consommation_moyenne']
    ecart_conso = conso_veh - conso_moyenne_categorie if conso_moyenne_categorie > 0 and conso_veh > 0 else 0
    ecart_conso_pct = (ecart_conso / conso_moyenne_categorie) * 100 if conso_moyenne_categorie > 0 and conso_veh > 0 else 0

    stats_conso = pd.DataFrame({
        'Param√®tre': [
            'Volume total', 'Co√ªt total', 'Nombre de prises', 'Moyenne par prise (Volume)', 'Moyenne par prise (Co√ªt)',
            'Prix moyen / Litre', 'Distance totale estim√©e', 'Consommation moyenne', 'Consommation moyenne (Cat√©gorie)',
            '√âcart vs Cat√©gorie', 'Co√ªt par Km'
        ],
        'Valeur': [
            f"{analyse['total_litres']:.1f} L", f"{analyse['cout_total']:,.0f} CFA", analyse['nb_prises'],
            f"{analyse['moyenne_prise']:.1f} L", f"{analyse['cout_moyen_prise']:,.0f} CFA", f"{analyse['prix_moyen_litre']:,.0f} CFA/L",
            f"{analyse.get('distance_totale_estimee', 0):,.0f} km",
            f"{conso_veh:.1f} L/100km" if conso_veh > 0 else "N/A",
            f"{conso_moyenne_categorie:.1f} L/100km" if conso_moyenne_categorie > 0 else "N/A",
            f"{ecart_conso:+.1f} L/100km ({ecart_conso_pct:+.1f}%)" if conso_veh > 0 and conso_moyenne_categorie > 0 else "N/A",
            f"{analyse['cout_par_km']:,.1f} CFA/km" if analyse['cout_par_km'] > 0 else "N/A"
        ]
    })

    return infos_base, stats_conso, analyse['conso_mensuelle'], analyse['stations_frequentes'], analyse # Retourne aussi l'analyse compl√®te


def calculer_kpis_globaux(df_transactions: pd.DataFrame, df_vehicules: pd.DataFrame, date_debut: datetime.date, date_fin: datetime.date, selected_categories: List[str]) -> Tuple[pd.DataFrame, pd.DataFrame]:
    """Calcule les KPIs de consommation et de co√ªt par cat√©gorie et v√©hicule."""
    df = df_transactions.merge(
        df_vehicules[['N¬∞ Carte', 'Cat√©gorie', 'Nouveau Immat']],
        left_on='Card num.', right_on='N¬∞ Carte', how='left'
    )
    # Filtrage date et cat√©gorie
    mask_date = (df['Date'].dt.date >= date_debut) & (df['Date'].dt.date <= date_fin)
    df = df[mask_date].copy()
    if selected_categories:
        df = df[df['Cat√©gorie'].isin(selected_categories)]

    if df.empty:
        return pd.DataFrame(), pd.DataFrame()

    vehicle_data = []
    df_sorted = df.sort_values(['Card num.', 'DateTime'])

    for card, group in df_sorted.groupby('Card num.'):
        if group.empty: continue

        total_lit = group['Quantity'].sum()
        total_amount = group['Amount'].sum()
        cat = group['Cat√©gorie'].iloc[0]
        immat = group['Nouveau Immat'].iloc[0]
        nb_prises = len(group)

        # Calcul distance robuste
        group_km = group[['Past mileage', 'Current mileage']].dropna()
        dist = 0
        if not group_km.empty and len(group_km) > 1:
             first_km = group_km['Past mileage'].iloc[0]
             last_km = group_km['Current mileage'].iloc[-1]
             if pd.notna(first_km) and pd.notna(last_km) and last_km > first_km:
                 dist = last_km - first_km
        # Fallback ou compl√©ment: somme des distances valides par transaction
        group['dist_transac'] = group['Current mileage'] - group['Past mileage']
        dist_sum_valid = group.loc[group['dist_transac'] > 0, 'dist_transac'].sum()
        distance_utilisee = max(dist, dist_sum_valid) # Prend le max des deux m√©thodes

        cons = (total_lit / distance_utilisee) * 100 if distance_utilisee > 0 else np.nan
        cpk = (total_amount / distance_utilisee) if distance_utilisee > 0 else np.nan
        avg_price_liter = (total_amount / total_lit) if total_lit > 0 else np.nan

        vehicle_data.append({
            'Card num.': card, 'Nouveau Immat': immat, 'Cat√©gorie': cat,
            'total_litres': total_lit, 'total_cout': total_amount,
            'distance': distance_utilisee, 'consommation': cons, 'cout_par_km': cpk,
            'nb_prises': nb_prises, 'prix_moyen_litre': avg_price_liter
        })

    df_vehicle_kpi = pd.DataFrame(vehicle_data)

    if df_vehicle_kpi.empty:
        return pd.DataFrame(), pd.DataFrame()

    # KPI par Cat√©gorie
    kpi_cat = df_vehicle_kpi.groupby('Cat√©gorie').agg(
        consommation_moyenne=('consommation', 'mean'), # Moyenne des consos individuelles
        cout_par_km_moyen=('cout_par_km', 'mean'),
        total_litres=('total_litres', 'sum'),
        total_cout=('total_cout', 'sum'),
        distance_totale=('distance', 'sum'),
        nb_vehicules=('Card num.', 'nunique'),
        nb_transactions=('nb_prises', 'sum')
    ).reset_index()

    # Ajouter conso globale par cat√©gorie (Total L / Total Km)
    kpi_cat['consommation_globale'] = (kpi_cat['total_litres'] / kpi_cat['distance_totale']) * 100
    kpi_cat['cout_par_km_global'] = kpi_cat['total_cout'] / kpi_cat['distance_totale']
    kpi_cat['prix_moyen_litre_global'] = kpi_cat['total_cout'] / kpi_cat['total_litres']


    # Arrondir pour affichage
    kpi_cat = kpi_cat.round({
        'consommation_moyenne': 1, 'cout_par_km_moyen': 1, 'total_litres': 0, 'total_cout': 0,
        'distance_totale': 0, 'consommation_globale': 1, 'cout_par_km_global': 1, 'prix_moyen_litre_global': 0
    })
    df_vehicle_kpi = df_vehicle_kpi.round({
         'total_litres': 1, 'total_cout': 0, 'distance': 0, 'consommation': 1, 'cout_par_km': 1,
         'prix_moyen_litre': 0
    })


    return kpi_cat, df_vehicle_kpi


# ---------------------------------------------------------------------
# Fonctions d'agr√©gation des anomalies pour les r√©sum√©s
# ---------------------------------------------------------------------

def calculer_score_risque(df_anomalies: pd.DataFrame) -> pd.DataFrame:
    """Calcule un score de risque pond√©r√© par v√©hicule bas√© sur les anomalies."""
    if df_anomalies.empty or 'poids_anomalie' not in df_anomalies.columns:
        return pd.DataFrame(columns=['Nouveau Immat', 'Card num.', 'Cat√©gorie', 'Nombre total anomalies', 'Score de risque'])

    # Compter les anomalies et sommer les poids par v√©hicule et type
    pivot = df_anomalies.groupby(['Nouveau Immat', 'Card num.', 'Cat√©gorie', 'type_anomalie']).agg(
        nombre=('type_anomalie', 'size'),
        score_partiel=('poids_anomalie', 'sum') # Somme des poids pour ce type d'anomalie
    ).reset_index()

    # Agr√©ger le score total et le nombre total par v√©hicule
    summary = pivot.groupby(['Nouveau Immat', 'Card num.', 'Cat√©gorie']).agg(
        nombre_total_anomalies=('nombre', 'sum'),
        score_risque=('score_partiel', 'sum')
    ).reset_index()

    # Fusionner pour avoir le d√©tail par type d'anomalie (facultatif, peut √™tre lourd)
    # summary_detailed = summary.merge(pivot.pivot_table(index=['Nouveau Immat', 'Card num.', 'Cat√©gorie'],
    #                                                   columns='type_anomalie',
    #                                                   values='nombre',
    #                                                   fill_value=0),
    #                                 left_on=['Nouveau Immat', 'Card num.', 'Cat√©gorie'],
    #                                 right_index=True).reset_index()

    return summary.sort_values('score_risque', ascending=False)

# ---------------------------------------------------------------------
# NOUVELLE FONCTION : Analyse consommation par p√©riode
# ---------------------------------------------------------------------
def analyser_consommation_par_periode(
    df_transactions: pd.DataFrame, 
    df_vehicules: pd.DataFrame, 
    date_debut: datetime.date, 
    date_fin: datetime.date, 
    periode: str = 'M', 
    selected_categories: List[str] = None,
    selected_vehicles: List[str] = None
) -> Tuple[pd.DataFrame, pd.DataFrame]:
    """
    Analyse la consommation de carburant par p√©riode (jour, semaine, mois, trimestre, ann√©e)
    
    Args:
        df_transactions: DataFrame des transactions
        df_vehicules: DataFrame des v√©hicules
        date_debut: Date de d√©but de l'analyse
        date_fin: Date de fin de l'analyse
        periode: P√©riode d'analyse ('D'=jour, 'W'=semaine, 'M'=mois, 'Q'=trimestre, 'Y'=ann√©e)
        selected_categories: Liste des cat√©gories √† inclure (None = toutes)
        selected_vehicles: Liste des v√©hicules √† inclure (None = tous)
        
    Returns:
        Tuple contenant:
            - DataFrame des consommations moyennes par p√©riode
            - DataFrame des consommations par v√©hicule et par p√©riode
    """
    # Fusionner les donn√©es de transactions avec les infos v√©hicules
    df = df_transactions.merge(
        df_vehicules[['N¬∞ Carte', 'Cat√©gorie', 'Nouveau Immat', 'Cap-r√®servoir']],
        left_on='Card num.', right_on='N¬∞ Carte', how='left'
    )
    
    # Filtrage date
    mask_date = (df['Date'].dt.date >= date_debut) & (df['Date'].dt.date <= date_fin)
    df = df[mask_date].copy()
    
    # Filtrage cat√©gorie si sp√©cifi√©
    if selected_categories:
        df = df[df['Cat√©gorie'].isin(selected_categories)]
        
    # Filtrage v√©hicule si sp√©cifi√©
    if selected_vehicles:
        df = df[df['Nouveau Immat'].isin(selected_vehicles)]
    
    if df.empty:
        return pd.DataFrame(), pd.DataFrame()
    
    # Ajouter les informations n√©cessaires pour l'analyse
    df['distance_parcourue'] = df['Current mileage'] - df['Past mileage']
    df['consommation_100km'] = np.where(
        (df['distance_parcourue'] > 0) & df['Quantity'].notna(),
        (df['Quantity'] / df['distance_parcourue']) * 100,
        np.nan
    )
    
    # R√©cup√©rer les seuils par cat√©gorie
    seuils_conso = st.session_state.get('ss_conso_seuils_par_categorie', {})
    
    # Ajouter colonne pour la p√©riode et formatage
    df['periode_datetime'] = df['Date'].dt.to_period(periode).dt.to_timestamp()
    
    if periode == 'D':
        df['periode_str'] = df['Date'].dt.strftime('%Y-%m-%d')
        format_periode = "Journali√®re"
    elif periode == 'W':
        df['periode_str'] = df['Date'].dt.to_period('W').astype(str)
        format_periode = "Hebdomadaire"
    elif periode == 'M':
        df['periode_str'] = df['Date'].dt.strftime('%Y-%m')
        format_periode = "Mensuelle"
    elif periode == 'Q':
        df['periode_str'] = df['Date'].dt.to_period('Q').astype(str)
        format_periode = "Trimestrielle"
    else:  # 'Y'
        df['periode_str'] = df['Date'].dt.strftime('%Y')
        format_periode = "Annuelle"
    
    # Analyser la consommation par v√©hicule et par p√©riode
    conso_veh_periode = df.groupby(['Nouveau Immat', 'Cat√©gorie', 'periode_str']).agg(
        volume_total=('Quantity', 'sum'),
        cout_total=('Amount', 'sum'),
        distance_totale=('distance_parcourue', lambda x: x[x > 0].sum()),  # Ne prendre que les distances positives
        nb_transactions=('Quantity', 'count'),
        date_debut_periode=('Date', 'min'),
        date_fin_periode=('Date', 'max')
    ).reset_index()
    
    # Calculer la consommation moyenne par p√©riode pour chaque v√©hicule
    conso_veh_periode['consommation_moyenne'] = np.where(
        conso_veh_periode['distance_totale'] > 0,
        (conso_veh_periode['volume_total'] / conso_veh_periode['distance_totale']) * 100,
        np.nan
    )
    
    # Ajouter le seuil correspondant √† chaque cat√©gorie
    conso_veh_periode['seuil_consommation'] = conso_veh_periode['Cat√©gorie'].map(
        lambda x: seuils_conso.get(x, DEFAULT_CONSO_SEUIL)
    )
    
    # Ajouter un indicateur d'exc√®s de consommation
    conso_veh_periode['exces_consommation'] = np.where(
        conso_veh_periode['consommation_moyenne'] > conso_veh_periode['seuil_consommation'],
        conso_veh_periode['consommation_moyenne'] - conso_veh_periode['seuil_consommation'],
        0
    )
    
    # Ajouter pourcentage d'exc√®s
    conso_veh_periode['pourcentage_exces'] = np.where(
        conso_veh_periode['seuil_consommation'] > 0,
        (conso_veh_periode['exces_consommation'] / conso_veh_periode['seuil_consommation']) * 100,
        0
    )
    
    # Agr√©ger par p√©riode pour toutes cat√©gories/v√©hicules
    conso_periode = df.groupby(['periode_str']).agg(
        volume_total=('Quantity', 'sum'),
        cout_total=('Amount', 'sum'),
        distance_totale=('distance_parcourue', lambda x: x[x > 0].sum()),
        nb_transactions=('Quantity', 'count'),
        nb_vehicules=('Nouveau Immat', 'nunique'),
        date_debut_periode=('Date', 'min'),
        date_fin_periode=('Date', 'max')
    ).reset_index()
    
    # Calculer la consommation moyenne globale par p√©riode
    conso_periode['consommation_moyenne'] = np.where(
        conso_periode['distance_totale'] > 0,
        (conso_periode['volume_total'] / conso_periode['distance_totale']) * 100,
        np.nan
    )
    
    # Arrondir les r√©sultats
    conso_veh_periode = conso_veh_periode.round({
        'volume_total': 1,
        'cout_total': 0,
        'distance_totale': 0,
        'consommation_moyenne': 1,
        'exces_consommation': 1,
        'pourcentage_exces': 1
    })
    
    conso_periode = conso_periode.round({
        'volume_total': 1,
        'cout_total': 0,
        'distance_totale': 0,
        'consommation_moyenne': 1
    })
    
    # Trier par p√©riode puis par exc√®s de consommation
    conso_veh_periode = conso_veh_periode.sort_values(['periode_str', 'exces_consommation'], ascending=[True, False])
    conso_periode = conso_periode.sort_values('periode_str')
    
    return conso_periode, conso_veh_periode

# ---------------------------------------------------------------------
# NOUVELLE FONCTION : Am√©lioration du dashboard
# ---------------------------------------------------------------------
def ameliorer_dashboard(df_transactions: pd.DataFrame, df_vehicules: pd.DataFrame, global_date_debut: datetime.date, global_date_fin: datetime.date, kpi_cat_dash: pd.DataFrame, df_vehicle_kpi_dash: pd.DataFrame):
    """Ajoute une section d'aper√ßu des exc√®s de consommation au tableau de bord"""
    
    with st.expander("‚ö†Ô∏è Aper√ßu des Exc√®s de Consommation (Mensuel)", expanded=True):
        # Calculer les exc√®s de consommation pour le dernier mois
        _, conso_veh_mois = analyser_consommation_par_periode(
            df_transactions, df_vehicules, global_date_debut, global_date_fin, 
            periode='M', selected_categories=None, selected_vehicles=None
        )
        
        if not conso_veh_mois.empty:
            # Filtrer seulement les exc√®s
            exces_mois = conso_veh_mois[conso_veh_mois['exces_consommation'] > 0]
            if not exces_mois.empty:
                nb_exces_mois = len(exces_mois)
                nb_vehicules_exces = exces_mois['Nouveau Immat'].nunique()
                
                col_e1, col_e2, col_e3 = st.columns(3)
                col_e1.metric("Nombre d'Exc√®s D√©tect√©s", f"{nb_exces_mois}")
                col_e2.metric("V√©hicules Concern√©s", f"{nb_vehicules_exces}")
                col_e3.metric("Exc√®s Moyen", f"{exces_mois['pourcentage_exces'].mean():.1f}%")
                
                # Top 5 des v√©hicules avec exc√®s
                top_exces = exces_mois.nlargest(5, 'pourcentage_exces')
                top_exces_display = top_exces[[
                    'periode_str', 'Nouveau Immat', 'consommation_moyenne',
                    'seuil_consommation', 'pourcentage_exces'
                ]]
                top_exces_display.columns = [
                    'P√©riode', 'Immatriculation', 'Consommation (L/100km)', 
                    'Seuil (L/100km)', 'Exc√®s (%)'
                ]
                
                st.dataframe(top_exces_display, use_container_width=True)
                
                st.markdown("""
                üëâ *Pour une analyse compl√®te des exc√®s de consommation, utilisez la page "Analyse par P√©riode"*
                """)
            else:
                st.success("‚úÖ Aucun exc√®s de consommation d√©tect√© pour les p√©riodes analys√©es.")
        else:
            st.info("Donn√©es insuffisantes pour l'analyse des exc√®s de consommation.")

# ---------------------------------------------------------------------
# NOUVELLE FONCTION : Affichage de la page d'analyse par p√©riode
# ---------------------------------------------------------------------
def afficher_page_analyse_periodes(df_transactions: pd.DataFrame, df_vehicules: pd.DataFrame, date_debut: datetime.date, date_fin: datetime.date):
    """Affiche la page d'analyse de consommation par p√©riode."""
    st.header(f"üìÖ Analyse de Consommation par P√©riode ({date_debut.strftime('%d/%m/%Y')} - {date_fin.strftime('%d/%m/%Y')})")
    
    if df_transactions.empty:
        st.warning("Aucune transaction √† analyser pour la p√©riode s√©lectionn√©e.")
        return
    
    # --- S√©lection de la p√©riode d'analyse ---
    st.subheader("Configuration de l'Analyse")
    col_config1, col_config2 = st.columns(2)
    
    with col_config1:
        periode_options = {
            'Jour': 'D',
            'Semaine': 'W',
            'Mois': 'M',
            'Trimestre': 'Q',
            'Ann√©e': 'Y'
        }
        periode_label = st.selectbox(
            "S√©lectionner la p√©riode d'analyse :",
            options=list(periode_options.keys()),
            index=2  # Mois par d√©faut
        )
        periode_code = periode_options[periode_label]
    
    with col_config2:
        # S√©lection des cat√©gories
        all_cats = sorted(df_vehicules['Cat√©gorie'].dropna().astype(str).unique())
        selected_cats = st.multiselect(
            "Filtrer par Cat√©gories de v√©hicules",
            options=all_cats,
            default=all_cats,
            key="periode_cat_filter"
        )
    
    # Option pour s√©lectionner des v√©hicules sp√©cifiques
    with st.expander("Filtrer par v√©hicules sp√©cifiques (optionnel)"):
        # Cr√©er une liste filtr√©e de v√©hicules si des cat√©gories sont s√©lectionn√©es
        if selected_cats:
            available_vehicles = sorted(df_vehicules[df_vehicules['Cat√©gorie'].isin(selected_cats)]['Nouveau Immat'].dropna().unique())
        else:
            available_vehicles = sorted(df_vehicules['Nouveau Immat'].dropna().unique())
        
        selected_vehicles = st.multiselect(
            "S√©lectionner des v√©hicules sp√©cifiques",
            options=available_vehicles,
            default=None,
            key="periode_veh_filter"
        )
    
    # --- Analyse et affichage des r√©sultats ---
    with st.spinner(f"Analyse {periode_label.lower()} en cours..."):
        conso_periode, conso_veh_periode = analyser_consommation_par_periode(
            df_transactions, df_vehicules, date_debut, date_fin, 
            periode=periode_code, selected_categories=selected_cats, 
            selected_vehicles=selected_vehicles if selected_vehicles else None
        )
    
    if conso_periode.empty or conso_veh_periode.empty:
        st.warning(f"Donn√©es insuffisantes pour l'analyse {periode_label.lower()}.")
        return
    
    # --- Vue globale par p√©riode ---
    st.subheader(f"Consommation {periode_label} Globale")
    
    # Afficher le tableau r√©capitulatif par p√©riode
    afficher_dataframe_avec_export(
        conso_periode[['periode_str', 'volume_total', 'cout_total', 'distance_totale', 
                      'consommation_moyenne', 'nb_transactions', 'nb_vehicules']],
        f"R√©capitulatif {periode_label}",
        key=f"recap_periode_{periode_code}"
    )
    
    # Graphique d'√©volution de la consommation moyenne par p√©riode
    fig_conso = px.line(
        conso_periode, x='periode_str', y='consommation_moyenne',
        title=f"√âvolution de la Consommation Moyenne ({periode_label})",
        labels={'periode_str': periode_label, 'consommation_moyenne': 'Conso. Moyenne (L/100km)'},
        markers=True
    )
    
    # Ajouter une ligne horizontale pour la moyenne globale
    conso_moy_globale = conso_periode['consommation_moyenne'].mean()
    fig_conso.add_hline(
        y=conso_moy_globale,
        line_dash="dash", line_color="green",
        annotation_text=f"Moyenne: {conso_moy_globale:.1f} L/100km"
    )
    
    st.plotly_chart(fig_conso, use_container_width=True)
    
    # Graphique d'√©volution du volume/co√ªt par p√©riode
    fig_vol_cout = px.bar(
        conso_periode, x='periode_str', y=['volume_total', 'cout_total'],
        title=f"Volume et Co√ªt par {periode_label}",
        labels={'periode_str': periode_label, 'value': 'Valeur', 'variable': 'M√©trique'},
        barmode='group'
    )
    st.plotly_chart(fig_vol_cout, use_container_width=True)
    
    # --- Vue d√©taill√©e par v√©hicule et p√©riode ---
    st.subheader(f"D√©tail par V√©hicule et par {periode_label}")
    
    # D√©tection des exc√®s de consommation
    exces_veh = conso_veh_periode[conso_veh_periode['exces_consommation'] > 0]
    nb_exces = len(exces_veh)
    
    if nb_exces > 0:
        st.warning(f"‚ö†Ô∏è D√©tect√© : {nb_exces} cas d'exc√®s de consommation sur la p√©riode.")
        
        # Tableau des exc√®s de consommation
        cols_display_exces = [
            'periode_str', 'Nouveau Immat', 'Cat√©gorie', 'consommation_moyenne',
            'seuil_consommation', 'exces_consommation', 'pourcentage_exces',
            'volume_total', 'distance_totale', 'nb_transactions'
        ]
        
        afficher_dataframe_avec_export(
            exces_veh[cols_display_exces],
            "Exc√®s de Consommation D√©tect√©s",
            key=f"exces_conso_{periode_code}"
        )
        
        # Graphique des plus grands exc√®s
        top_exces = exces_veh.nlargest(10, 'pourcentage_exces')
        fig_top_exces = px.bar(
            top_exces,
            x='Nouveau Immat',
            y='pourcentage_exces',
            color='Cat√©gorie',
            title="Top 10 des Exc√®s de Consommation (%)",
            labels={'pourcentage_exces': "Exc√®s (%)", 'Nouveau Immat': 'V√©hicule'},
            hover_data=['periode_str', 'consommation_moyenne', 'seuil_consommation']
        )
        st.plotly_chart(fig_top_exces, use_container_width=True)
    else:
        st.success("‚úÖ Aucun exc√®s de consommation d√©tect√© sur la p√©riode analys√©e.")
    
    # Vue d√©taill√©e de toutes les donn√©es par v√©hicule et p√©riode
    with st.expander("Voir toutes les donn√©es d√©taill√©es par v√©hicule et p√©riode"):
        cols_display_detail = [
            'periode_str', 'Nouveau Immat', 'Cat√©gorie', 'volume_total',
            'distance_totale', 'consommation_moyenne', 'seuil_consommation',
            'exces_consommation', 'pourcentage_exces', 'cout_total', 'nb_transactions'
        ]
        
        afficher_dataframe_avec_export(
            conso_veh_periode[cols_display_detail],
            f"Toutes les donn√©es par V√©hicule et {periode_label}",
            key=f"all_data_periode_{periode_code}"
        )
    
    # --- Analyse comparative inter-p√©riodes ---
    with st.expander("Analyse comparative entre p√©riodes", expanded=False):
        st.info("Cette section permet de visualiser l'√©volution de la consommation par v√©hicule √† travers les p√©riodes.")
        
        # S√©lectionner un v√©hicule pour l'analyse d√©taill√©e
        vehicules_list = sorted(conso_veh_periode['Nouveau Immat'].unique())
        if vehicules_list:
            vehicule_selected = st.selectbox(
                "S√©lectionner un v√©hicule pour l'analyse d√©taill√©e :",
                options=vehicules_list,
                key="compare_vehicule_select"
            )
            
            # Filtrer les donn√©es pour ce v√©hicule
            veh_data = conso_veh_periode[conso_veh_periode['Nouveau Immat'] == vehicule_selected]
            
            if not veh_data.empty:
                # Graphique d'√©volution de la consommation pour ce v√©hicule
                fig_veh_evo = px.line(
                    veh_data, x='periode_str', y=['consommation_moyenne', 'seuil_consommation'],
                    title=f"√âvolution de la Consommation - {vehicule_selected}",
                    labels={'periode_str': periode_label, 'value': 'Consommation (L/100km)', 'variable': 'M√©trique'},
                    markers=True
                )
                st.plotly_chart(fig_veh_evo, use_container_width=True)
                
                # Tableau d'√©volution
                st.dataframe(veh_data[[
                    'periode_str', 'consommation_moyenne', 'seuil_consommation',
                    'exces_consommation', 'volume_total', 'distance_totale'
                ]], use_container_width=True)
            else:
                st.info(f"Pas de donn√©es disponibles pour {vehicule_selected} sur les p√©riodes s√©lectionn√©es.")
        else:
            st.info("Aucun v√©hicule avec donn√©es suffisantes pour l'analyse comparative.")

# ---------------------------------------------------------------------
# Fonctions d'Affichage des Pages
# ---------------------------------------------------------------------

def afficher_page_dashboard(df_transactions: pd.DataFrame, df_vehicules: pd.DataFrame, df_ge: pd.DataFrame, df_autres: pd.DataFrame, date_debut: datetime.date, date_fin: datetime.date):
    """Affiche le tableau de bord principal."""
    st.header(f"üìä Tableau de Bord Principal ({date_debut.strftime('%d/%m/%Y')} - {date_fin.strftime('%d/%m/%Y')})")

    if df_transactions.empty:
        st.warning("Aucune transaction √† analyser pour la p√©riode s√©lectionn√©e.")
        return

    # --- Calcul des KPIs et Alertes ---
    total_volume = df_transactions['Quantity'].sum()
    total_cout = df_transactions['Amount'].sum()
    nb_transactions = len(df_transactions)
    cartes_veh_actives = df_transactions[df_transactions['Card num.'].isin(df_vehicules['N¬∞ Carte'])]['Card num.'].nunique()
    prix_moyen_litre_global = (total_cout / total_volume) if total_volume > 0 else 0

    # Calcul conso moyenne globale (plus complexe, bas√© sur KPI)
    kpi_cat_dash, df_vehicle_kpi_dash = calculer_kpis_globaux(df_transactions, df_vehicules, date_debut, date_fin, list(st.session_state.ss_conso_seuils_par_categorie.keys()))
    conso_moyenne_globale = (kpi_cat_dash['total_litres'].sum() / kpi_cat_dash['distance_totale'].sum()) * 100 if not kpi_cat_dash.empty and kpi_cat_dash['distance_totale'].sum() > 0 else 0
    cout_km_global = (kpi_cat_dash['total_cout'].sum() / kpi_cat_dash['distance_totale'].sum()) if not kpi_cat_dash.empty and kpi_cat_dash['distance_totale'].sum() > 0 else 0


    # D√©tection anomalies pour alertes
    df_anomalies_dash = detecter_anomalies(df_transactions, df_vehicules)
    cartes_inconnues_dash = verifier_cartes_inconnues(df_transactions, df_vehicules, df_ge, df_autres)
    vehicules_risques_dash = calculer_score_risque(df_anomalies_dash)
    nb_vehicules_suspects = len(vehicules_risques_dash[vehicules_risques_dash['score_risque'] >= st.session_state.ss_seuil_anomalies_suspectes_score]) if not vehicules_risques_dash.empty else 0
    nb_anomalies_critiques = len(df_anomalies_dash[df_anomalies_dash['poids_anomalie'] >= 8]) if not df_anomalies_dash.empty else 0 # Ex: Poids >= 8


    # --- Affichage KPIs ---
    st.subheader("üöÄ Indicateurs Cl√©s")
    col1, col2, col3, col4 = st.columns(4)
    col1.metric("Volume Total", f"{total_volume:,.0f} L")
    col2.metric("Co√ªt Total", f"{total_cout:,.0f} CFA")
    col3.metric("Transactions", f"{nb_transactions:,}")
    col4.metric("V√©hicules Actifs", f"{cartes_veh_actives:,}")

    col5, col6, col7, col8 = st.columns(4)
    col5.metric("Conso. Moyenne Globale", f"{conso_moyenne_globale:.1f} L/100km" if conso_moyenne_globale else "N/A")
    col6.metric("Co√ªt Moyen / Km Global", f"{cout_km_global:.1f} CFA/km" if cout_km_global else "N/A")
    col7.metric("Prix Moyen / Litre", f"{prix_moyen_litre_global:,.0f} CFA/L" if prix_moyen_litre_global else "N/A")
    # col8.metric("placeholder", "...") # Espace pour autre KPI

    # --- Affichage Alertes Rapides ---
    st.subheader("‚ö†Ô∏è Alertes Rapides")
    col_a1, col_a2, col_a3 = st.columns(3)
    col_a1.metric("Cartes Inconnues", len(cartes_inconnues_dash), delta_color="inverse")
    col_a2.metric(f"V√©hicules Suspects (Score > {st.session_state.ss_seuil_anomalies_suspectes_score})", nb_vehicules_suspects, delta_color="inverse")
    col_a3.metric("Anomalies Critiques (Poids >= 8)", nb_anomalies_critiques, delta_color="inverse")

    # --- Affichage Graphiques Cl√©s ---
    st.subheader("üìà Graphiques Cl√©s")

    # √âvolution Volume & Co√ªt
    with st.expander("√âvolution Mensuelle Volume & Co√ªt", expanded=True):
        evo_mensuelle = df_transactions.groupby(pd.Grouper(key='Date', freq='M')).agg(
            Volume_L=('Quantity', 'sum'),
            Cout_CFA=('Amount', 'sum')
        ).reset_index()
        evo_mensuelle['Mois'] = evo_mensuelle['Date'].dt.strftime('%Y-%m')
        fig_evo = px.bar(evo_mensuelle, x='Mois', y=['Volume_L', 'Cout_CFA'],
                         title="√âvolution Mensuelle du Volume et du Co√ªt",
                         labels={'value': 'Valeur', 'variable': 'Indicateur'}, barmode='group')
        fig_evo.update_layout(yaxis_title="Volume (L) / Co√ªt (CFA)")
        st.plotly_chart(fig_evo, use_container_width=True)

    # R√©partition par Cat√©gorie
    with st.expander("R√©partition par Cat√©gorie de V√©hicule", expanded=False):
        if not kpi_cat_dash.empty:
             col_g1, col_g2 = st.columns(2)
             fig_pie_vol = px.pie(kpi_cat_dash, values='total_litres', names='Cat√©gorie', title='R√©partition Volume par Cat√©gorie')
             col_g1.plotly_chart(fig_pie_vol, use_container_width=True)
             fig_pie_cout = px.pie(kpi_cat_dash, values='total_cout', names='Cat√©gorie', title='R√©partition Co√ªt par Cat√©gorie')
             col_g2.plotly_chart(fig_pie_cout, use_container_width=True)
        else:
             st.info("Donn√©es insuffisantes pour la r√©partition par cat√©gorie.")

    # Top V√©hicules
    with st.expander("Top 5 V√©hicules (Co√ªt / Volume / Anomalies)", expanded=False):
        if not df_vehicle_kpi_dash.empty:
             col_t1, col_t2 = st.columns(2)
             top_cout = df_vehicle_kpi_dash.nlargest(5, 'total_cout')[['Nouveau Immat', 'total_cout']]
             top_volume = df_vehicle_kpi_dash.nlargest(5, 'total_litres')[['Nouveau Immat', 'total_litres']]
             afficher_dataframe_avec_export(top_cout, "Top 5 Co√ªt Total", key="dash_top_cout")
             afficher_dataframe_avec_export(top_volume, "Top 5 Volume Total", key="dash_top_vol")
        else:
            st.info("Donn√©es insuffisantes pour le classement des v√©hicules.")

        if not vehicules_risques_dash.empty:
             top_risque = vehicules_risques_dash.nlargest(5, 'score_risque')[['Nouveau Immat', 'score_risque', 'nombre_total_anomalies']]
             afficher_dataframe_avec_export(top_risque, "Top 5 Score Risque", key="dash_top_risque")
        else:
             st.info("Aucune anomalie d√©tect√©e pour le classement par risque.")

    # Afficher cartes inconnues si pr√©sentes
    if not cartes_inconnues_dash.empty:
        with st.expander("üö® Cartes Inconnues D√©tect√©es", expanded=False):
            afficher_dataframe_avec_export(cartes_inconnues_dash, "D√©tail des Cartes Inconnues", key="dash_cartes_inconnues")


def afficher_page_analyse_vehicules(df_transactions: pd.DataFrame, df_vehicules: pd.DataFrame, date_debut_globale: datetime.date, date_fin_globale: datetime.date, kpi_categories: pd.DataFrame):
    """Affiche la page d'analyse d√©taill√©e par v√©hicule."""
    st.header("üöó Analyse D√©taill√©e par V√©hicule")

    veh_list = ["S√©lectionner un v√©hicule..."] + sorted(df_vehicules['Nouveau Immat'].dropna().unique())
    vehicule_immat = st.selectbox("Choisir un v√©hicule par immatriculation", veh_list, index=0)

    if vehicule_immat == "S√©lectionner un v√©hicule...":
        st.info("Veuillez s√©lectionner un v√©hicule dans la liste d√©roulante.")
        # Optionnel: Afficher un r√©sum√© global ici si aucun v√©hicule n'est choisi
        st.subheader("Statistiques Globales (tous v√©hicules sur p√©riode)")
        if not kpi_categories.empty:
            kpi_cat_sum = kpi_categories[[
                 'Cat√©gorie', 'nb_vehicules', 'nb_transactions', 'total_litres', 'total_cout',
                 'distance_totale', 'consommation_globale', 'cout_par_km_global', 'prix_moyen_litre_global'
            ]]
            afficher_dataframe_avec_export(kpi_cat_sum, "R√©sum√© par Cat√©gorie", key="veh_global_cat_summary")
        else:
            st.warning("Aucune donn√©e KPI √† afficher.")
        return

    # --- Filtrage donn√©es pour le v√©hicule s√©lectionn√© ---
    try:
        info_vehicule = df_vehicules[df_vehicules['Nouveau Immat'] == vehicule_immat].iloc[0]
        carte_veh = info_vehicule['N¬∞ Carte']
    except IndexError:
        st.error(f"Impossible de trouver les informations pour le v√©hicule {vehicule_immat}.")
        return

    data_veh = df_transactions[df_transactions['Card num.'] == carte_veh].copy()

    if data_veh.empty:
        st.warning(f"Aucune transaction trouv√©e pour le v√©hicule {vehicule_immat} sur la p√©riode s√©lectionn√©e ({date_debut_globale.strftime('%d/%m/%Y')} - {date_fin_globale.strftime('%d/%m/%Y')}).")
        # Afficher quand m√™me les infos de base
        infos_base_vide = pd.DataFrame({
             'Param√®tre': ['Immatriculation', 'Marque', 'Mod√®le', 'Type', 'Cat√©gorie', 'Capacit√© r√©servoir', 'P√©riode d√©but', 'P√©riode fin'],
             'Valeur': [
                info_vehicule.get('Nouveau Immat', 'N/A'), info_vehicule.get('Marque', 'N/A'), info_vehicule.get('Mod√®le', 'N/A'),
                info_vehicule.get('Type', 'N/A'), info_vehicule.get('Cat√©gorie', 'N/A'), f"{info_vehicule.get('Cap-r√®servoir', 0):.0f} L",
                date_debut_globale.strftime(DATE_FORMAT), date_fin_globale.strftime(DATE_FORMAT)
             ]
        })
        afficher_dataframe_avec_export(infos_base_vide, "Informations du v√©hicule", key="df_infos_veh_vide")
        return

    st.subheader(f"Analyse du v√©hicule : {vehicule_immat} ({info_vehicule.get('Marque','')} {info_vehicule.get('Mod√®le','')})")

    # --- R√©cup√©rer Conso Moyenne Cat√©gorie pour Benchmarking ---
    categorie_veh = info_vehicule.get('Cat√©gorie', 'N/A')
    conso_moyenne_cat = 0.0
    if not kpi_categories.empty and categorie_veh != 'N/A':
        ligne_cat = kpi_categories[kpi_categories['Cat√©gorie'] == categorie_veh]
        if not ligne_cat.empty:
            # Utiliser 'consommation_globale' pour le benchmark car plus repr√©sentatif
            conso_moyenne_cat = ligne_cat['consommation_globale'].iloc[0]

    # --- G√©n√©rer et Afficher Rapport ---
    infos_base, stats_conso, conso_mensuelle, stations_freq, analyse_detail = generer_rapport_vehicule(
        data_veh, info_vehicule, date_debut_globale, date_fin_globale, conso_moyenne_cat
    )

    col_info1, col_info2 = st.columns(2)
    with col_info1:
        afficher_dataframe_avec_export(infos_base, "Informations V√©hicule", key=f"infos_{vehicule_immat}")
    with col_info2:
        afficher_dataframe_avec_export(stats_conso, "Statistiques Consommation & Co√ªt", key=f"stats_{vehicule_immat}")

    # --- Graphiques sp√©cifiques au v√©hicule ---
    st.markdown("### Graphiques")
    with st.expander("Graphiques d√©taill√©s du v√©hicule", expanded=False):
        col_g1, col_g2 = st.columns(2)
        # Consommation journali√®re
        fig_line = px.line(data_veh.sort_values('Date'), x='Date', y='Quantity', title="Consommation Journali√®re (Volume)", markers=True)
        col_g1.plotly_chart(fig_line, use_container_width=True)
        # Distribution des volumes
        fig_hist = px.histogram(data_veh, x='Quantity', title="Distribution des Volumes Pris", nbins=20)
        col_g2.plotly_chart(fig_hist, use_container_width=True)
        # Consommation mensuelle
        if not conso_mensuelle.empty:
             fig_mens = px.bar(conso_mensuelle.reset_index(), x='mois', y=['Volume_L', 'Montant_CFA'], title="√âvolution Mensuelle (Volume & Co√ªt)", barmode='group')
             st.plotly_chart(fig_mens, use_container_width=True)

    # --- Stations fr√©quent√©es ---
    st.markdown("### Stations")
    with st.expander("Stations les plus fr√©quent√©es", expanded=False):
        if not stations_freq.empty:
            station_df = stations_freq.reset_index()
            station_df.columns = ['Place', 'Nombre de visites']
            afficher_dataframe_avec_export(station_df, "Top 5 Stations", key=f"stations_{vehicule_immat}")
        else:
            st.info("Aucune donn√©e de station disponible.")

    # --- Anomalies sp√©cifiques au v√©hicule ---
    st.markdown("### Anomalies D√©tect√©es")
    with st.expander("D√©tail des anomalies pour ce v√©hicule", expanded=True):
        anomalies_all = detecter_anomalies(df_transactions, df_vehicules) # Red√©tecter sur la p√©riode filtr√©e globale
        anomalies_veh = anomalies_all[anomalies_all['Card num.'] == carte_veh].copy()

        if not anomalies_veh.empty:
            score_veh = anomalies_veh['poids_anomalie'].sum()
            nb_anom_veh = len(anomalies_veh)
            st.warning(f"üö® {nb_anom_veh} anomalie(s) d√©tect√©e(s) pour ce v√©hicule (Score de risque total: {score_veh}).")

            # Afficher tableau d√©taill√© des anomalies
            cols_display_anom = ['Date', 'Hour', 'type_anomalie', 'detail_anomalie', 'Quantity', 'Amount', 'distance_parcourue', 'consommation_100km', 'Place', 'poids_anomalie']
            cols_final_anom = [col for col in cols_display_anom if col in anomalies_veh.columns]
            afficher_dataframe_avec_export(anomalies_veh[cols_final_anom], "Liste des Anomalies", key=f"anom_detail_{vehicule_immat}")

            # R√©sum√© par type d'anomalie pour ce v√©hicule
            summary_anom_veh = anomalies_veh.groupby('type_anomalie').agg(
                 Nombre=('type_anomalie','size'),
                 Score_Partiel=('poids_anomalie','sum')
            ).reset_index().sort_values('Score_Partiel', ascending=False)
            afficher_dataframe_avec_export(summary_anom_veh, "R√©sum√© des Anomalies par Type", key=f"anom_summary_{vehicule_immat}")

        else:
            st.success("‚úÖ Aucune anomalie d√©tect√©e pour ce v√©hicule sur la p√©riode s√©lectionn√©e.")


def afficher_page_analyse_couts(df_transactions: pd.DataFrame, df_vehicules: pd.DataFrame, date_debut: datetime.date, date_fin: datetime.date):
    """Affiche la page d'analyse des co√ªts."""
    st.header(f"üí∞ Analyse des Co√ªts ({date_debut.strftime('%d/%m/%Y')} - {date_fin.strftime('%d/%m/%Y')})")

    if df_transactions.empty:
        st.warning("Aucune transaction √† analyser pour la p√©riode s√©lectionn√©e.")
        return

    # Calculer KPIs incluant CpK
    kpi_cat, df_vehicle_kpi = calculer_kpis_globaux(
        df_transactions, df_vehicules, date_debut, date_fin,
        list(st.session_state.ss_conso_seuils_par_categorie.keys()) # Toutes cat√©gories
    )

    if df_vehicle_kpi.empty:
         st.warning("Impossible de calculer les indicateurs de co√ªts (donn√©es de kilom√©trage ou transactions insuffisantes).")
         return

    tab1, tab2, tab3 = st.tabs(["üìä Co√ªt par Km (CpK)", "üìà Tendances des Co√ªts", "‚õΩ Analyse par Station"])

    with tab1:
        st.subheader("Co√ªt par Kilom√®tre (CpK) par V√©hicule")
        cpk_veh = df_vehicle_kpi[['Nouveau Immat', 'Cat√©gorie', 'cout_par_km', 'distance', 'total_cout']].dropna(subset=['cout_par_km']).sort_values('cout_par_km', ascending=False)
        afficher_dataframe_avec_export(cpk_veh, "Classement CpK par V√©hicule", key="cpk_veh_table")

        st.subheader("Co√ªt par Kilom√®tre (CpK) Moyen par Cat√©gorie")
        if not kpi_cat.empty:
            cpk_cat = kpi_cat[['Cat√©gorie', 'cout_par_km_global', 'distance_totale', 'total_cout']].dropna(subset=['cout_par_km_global']).sort_values('cout_par_km_global', ascending=False)
            afficher_dataframe_avec_export(cpk_cat, "CpK Moyen par Cat√©gorie", key="cpk_cat_table")

            fig_cpk_cat = px.bar(cpk_cat, x='Cat√©gorie', y='cout_par_km_global', title="Co√ªt Moyen par Km Global par Cat√©gorie", labels={'cout_par_km_global': 'CpK Global (CFA/km)'})
            st.plotly_chart(fig_cpk_cat, use_container_width=True)
        else:
            st.info("Donn√©es insuffisantes pour l'analyse CpK par cat√©gorie.")

    with tab2:
        st.subheader("Tendances Mensuelles des Co√ªts")
        evo_mensuelle_cout = df_transactions.groupby(pd.Grouper(key='Date', freq='M')).agg(
            Cout_Total_CFA=('Amount', 'sum'),
            Volume_Total_L=('Quantity', 'sum')
        ).reset_index()
        evo_mensuelle_cout['Mois'] = evo_mensuelle_cout['Date'].dt.strftime('%Y-%m')
        evo_mensuelle_cout['Prix_Moyen_L'] = evo_mensuelle_cout['Cout_Total_CFA'] / evo_mensuelle_cout['Volume_Total_L']

        fig_trend_cout = px.line(evo_mensuelle_cout, x='Mois', y='Cout_Total_CFA', title="√âvolution Mensuelle du Co√ªt Total", markers=True, labels={'Cout_Total_CFA': 'Co√ªt Total (CFA)'})
        st.plotly_chart(fig_trend_cout, use_container_width=True)

        fig_trend_prix_l = px.line(evo_mensuelle_cout, x='Mois', y='Prix_Moyen_L', title="√âvolution Mensuelle du Prix Moyen au Litre", markers=True, labels={'Prix_Moyen_L': 'Prix Moyen (CFA/L)'})
        st.plotly_chart(fig_trend_prix_l, use_container_width=True)

        st.subheader("Transactions les Plus Co√ªteuses")
        # 1. Get top 10 transactions by Amount
        top_trans_base = df_transactions.nlargest(10, 'Amount')
        # 2. Merge with vehicle info
        top_transactions_merged = top_trans_base.merge(
            df_vehicules[['N¬∞ Carte', 'Nouveau Immat', 'Cat√©gorie']],
            left_on='Card num.',
            right_on='N¬∞ Carte',
            how='left'
        )
        # 3. Select columns for display
        cols_to_display_top = ['Date', 'Hour', 'Nouveau Immat', 'Cat√©gorie', 'Quantity', 'Amount', 'Place', 'Card num.']
        # Keep only existing columns to avoid errors if merge failed or columns missing
        cols_final_top = [col for col in cols_to_display_top if col in top_transactions_merged.columns]
        afficher_dataframe_avec_export(top_transactions_merged[cols_final_top], "Top 10 Transactions par Montant", key="top_transac_amount")


    with tab3:
         st.subheader("Analyse des Co√ªts par Station")
         # V√©rifier si la colonne 'Place' existe
         if 'Place' in df_transactions.columns:
             analyse_station = df_transactions.groupby('Place').agg(
                 Volume_Total_L=('Quantity', 'sum'),
                 Cout_Total_CFA=('Amount', 'sum'),
                 Nb_Transactions=('Quantity', 'count')
             ).reset_index()
             analyse_station['Prix_Moyen_L'] = analyse_station['Cout_Total_CFA'] / analyse_station['Volume_Total_L']
             analyse_station = analyse_station[analyse_station['Volume_Total_L'] > 0].sort_values('Cout_Total_CFA', ascending=False)

             if not analyse_station.empty:
                 afficher_dataframe_avec_export(analyse_station, "R√©sum√© par Station", key="station_summary")

                 col_s1, col_s2 = st.columns(2)
                 top_n_stations = 15 # Nombre de stations √† afficher dans les graphiques
                 fig_station_cout = px.bar(analyse_station.head(top_n_stations), x='Place', y='Cout_Total_CFA', title=f"Top {top_n_stations} Stations par Co√ªt Total", labels={'Cout_Total_CFA': 'Co√ªt Total (CFA)'})
                 col_s1.plotly_chart(fig_station_cout, use_container_width=True)

                 fig_station_prix = px.bar(analyse_station.head(top_n_stations).sort_values('Prix_Moyen_L', ascending=False), x='Place', y='Prix_Moyen_L', title=f"Top {top_n_stations} Stations par Prix Moyen / Litre", labels={'Prix_Moyen_L': 'Prix Moyen (CFA/L)'})
                 col_s2.plotly_chart(fig_station_prix, use_container_width=True)
             else:
                 st.info("Aucune donn√©e de transaction avec information de station valide trouv√©e.")
         else:
             st.warning("La colonne 'Place' (nom de la station) est manquante dans le fichier de transactions pour effectuer cette analyse.")


def afficher_page_anomalies(df_transactions: pd.DataFrame, df_vehicules: pd.DataFrame, date_debut: datetime.date, date_fin: datetime.date):
    """Affiche la page de synth√®se des anomalies."""
    st.header(f"üö® D√©tection des Anomalies ({date_debut.strftime('%d/%m/%Y')} - {date_fin.strftime('%d/%m/%Y')})")

    if df_transactions.empty:
        st.warning("Aucune transaction √† analyser pour la p√©riode s√©lectionn√©e.")
        return

    # --- D√©tection & Calcul Score ---
    with st.spinner("D√©tection des anomalies en cours..."):
         df_anomalies = detecter_anomalies(df_transactions, df_vehicules)
         df_scores = calculer_score_risque(df_anomalies)

    if df_anomalies.empty:
        st.success("‚úÖ Aucune anomalie d√©tect√©e sur la p√©riode s√©lectionn√©e !")
        return

    nb_total_anomalies = len(df_anomalies)
    nb_vehicules_avec_anomalies = df_anomalies['Card num.'].nunique()
    st.warning(f"D√©tect√© : **{nb_total_anomalies:,}** anomalies concernant **{nb_vehicules_avec_anomalies:,}** v√©hicules.")

    # --- Tableau des V√©hicules Suspects (bas√© sur score) ---
    st.subheader(f"üéØ V√©hicules Suspects (Score de Risque ‚â• {st.session_state.ss_seuil_anomalies_suspectes_score})")
    vehicules_suspects = df_scores[df_scores['score_risque'] >= st.session_state.ss_seuil_anomalies_suspectes_score]

    if not vehicules_suspects.empty:
        # Ajouter le d√©tail du nombre par type d'anomalie (pivot)
        pivot_details = df_anomalies.groupby(['Nouveau Immat', 'Card num.', 'Cat√©gorie', 'type_anomalie']).size().unstack(fill_value=0)
        vehicules_suspects_details = vehicules_suspects.merge(pivot_details, on=['Nouveau Immat', 'Card num.', 'Cat√©gorie'], how='left')
        afficher_dataframe_avec_export(vehicules_suspects_details, f"Liste des {len(vehicules_suspects)} V√©hicules Suspects", key="anom_suspects_score")

        # Option pour voir le d√©tail des transactions des suspects
        with st.expander("Voir les transactions d√©taill√©es des v√©hicules suspects"):
            details_suspects = df_anomalies[df_anomalies['Card num.'].isin(vehicules_suspects['Card num.'])]
            cols_display_detail = ['Date', 'Hour', 'Nouveau Immat', 'Cat√©gorie', 'type_anomalie', 'detail_anomalie', 'Quantity', 'Amount', 'Place', 'poids_anomalie']
            cols_final_detail = [col for col in cols_display_detail if col in details_suspects.columns]
            # Remove redundant sort, data is already sorted by detecter_anomalies
            afficher_dataframe_avec_export(details_suspects[cols_final_detail], "D√©tail Transactions des Suspects", key="anom_suspects_details_transac")
    else:
        st.info("Aucun v√©hicule n'atteint le seuil de score de risque suspect.")

    # --- Synth√®se par Type d'Anomalie ---
    st.subheader("üìä Synth√®se par Type d'Anomalie")
    summary_type = df_anomalies.groupby('type_anomalie').agg(
        Nombre=('type_anomalie', 'size'),
        Score_Total=('poids_anomalie', 'sum'),
        Nb_Vehicules_Touches=('Card num.', 'nunique')
    ).reset_index().sort_values('Score_Total', ascending=False)
    afficher_dataframe_avec_export(summary_type, "Nombre et Score par Type d'Anomalie", key="anom_summary_type")

    fig_summary_type = px.bar(summary_type, x='type_anomalie', y='Nombre', title="Nombre d'Anomalies par Type", color='Score_Total', labels={'Nombre':"Nombre d'occurrences", 'type_anomalie':'Type d\'Anomalie'})
    st.plotly_chart(fig_summary_type, use_container_width=True)


    # --- Vue d√©taill√©e de toutes les anomalies ---
    with st.expander("Voir toutes les anomalies d√©tect√©es (tableau complet)"):
         cols_display_all = ['Date', 'Hour', 'Nouveau Immat', 'Cat√©gorie', 'type_anomalie', 'detail_anomalie', 'Quantity', 'Amount', 'Place', 'poids_anomalie']
         cols_final_all = [col for col in cols_display_all if col in df_anomalies.columns]
         afficher_dataframe_avec_export(df_anomalies[cols_final_all], "Tableau Complet des Anomalies", key="anom_all_details")


def afficher_page_kpi(df_transactions: pd.DataFrame, df_vehicules: pd.DataFrame, date_debut: datetime.date, date_fin: datetime.date):
    """Affiche la page des Indicateurs Cl√©s de Performance."""
    st.header(f"üìà Indicateurs Cl√©s de Performance (KPIs) ({date_debut.strftime('%d/%m/%Y')} - {date_fin.strftime('%d/%m/%Y')})")

    if df_transactions.empty:
        st.warning("Aucune transaction √† analyser pour la p√©riode s√©lectionn√©e.")
        return

    all_cats = sorted(df_vehicules['Cat√©gorie'].dropna().astype(str).unique())
    selected_cats_kpi = st.multiselect(
        "Filtrer par Cat√©gories de v√©hicules",
        options=all_cats,
        default=all_cats,
        key="kpi_cat_filter"
    )

    # --- Calcul des KPIs ---
    with st.spinner("Calcul des KPIs..."):
        kpi_categories, df_vehicle_kpi = calculer_kpis_globaux(
            df_transactions, df_vehicules, date_debut, date_fin, selected_cats_kpi
        )

    if kpi_categories.empty or df_vehicle_kpi.empty:
        st.warning("Donn√©es insuffisantes pour calculer les KPIs pour les cat√©gories s√©lectionn√©es.")
        return

    # --- Affichage KPIs par Cat√©gorie ---
    st.subheader("KPIs Agr√©g√©s par Cat√©gorie")
    cols_kpi_cat_display = [
        'Cat√©gorie', 'nb_vehicules', 'nb_transactions', 'total_litres', 'total_cout',
        'distance_totale', 'consommation_globale', 'cout_par_km_global', 'prix_moyen_litre_global'
    ]
    afficher_dataframe_avec_export(kpi_categories[cols_kpi_cat_display], f"KPIs pour {len(kpi_categories)} cat√©gorie(s)", key="kpi_cat_table")

    col_gkpi1, col_gkpi2 = st.columns(2)
    fig_kpi_conso = px.bar(kpi_categories, x='Cat√©gorie', y='consommation_globale', title="Consommation Globale par Cat√©gorie", labels={'consommation_globale': 'Consommation (L/100km)'})
    col_gkpi1.plotly_chart(fig_kpi_conso, use_container_width=True)
    fig_kpi_cpk = px.bar(kpi_categories, x='Cat√©gorie', y='cout_par_km_global', title="Co√ªt par Km Global par Cat√©gorie", labels={'cout_par_km_global': 'Co√ªt par Km (CFA/km)'})
    col_gkpi2.plotly_chart(fig_kpi_cpk, use_container_width=True)

    # --- Affichage KPIs par V√©hicule ---
    with st.expander("Voir les KPIs d√©taill√©s par v√©hicule"):
        cols_kpi_veh_display = [
            'Nouveau Immat', 'Cat√©gorie', 'nb_prises', 'total_litres', 'total_cout',
            'distance', 'consommation', 'cout_par_km', 'prix_moyen_litre'
        ]
        afficher_dataframe_avec_export(df_vehicle_kpi[cols_kpi_veh_display], f"KPIs pour {len(df_vehicle_kpi)} v√©hicule(s)", key="kpi_veh_table")

    # --- Analyse Tendances Anomalies (Optionnel - peut √™tre lourd) ---
    with st.expander("üìà Analyse des Tendances d'Anomalies", expanded=False):
        st.info("L'analyse des tendances d'anomalies peut prendre du temps.")
        if st.button("Lancer l'analyse des tendances", key="btn_trend_anom"):
             with st.spinner("Calcul des tendances d'anomalies..."):
                 df_anomalies_kpi = detecter_anomalies(df_transactions, df_vehicules) # Sur la p√©riode filtr√©e
                 if not df_anomalies_kpi.empty:
                     # Filtrer par cat√©gories s√©lectionn√©es
                     df_anomalies_kpi = df_anomalies_kpi[df_anomalies_kpi['Cat√©gorie'].isin(selected_cats_kpi)]

                     if not df_anomalies_kpi.empty:
                         df_anomalies_kpi['Mois'] = df_anomalies_kpi['Date'].dt.to_period('M').astype(str)
                         trend_anom = df_anomalies_kpi.groupby(['Mois', 'type_anomalie']).size().reset_index(name='Nombre')

                         fig_trend = px.line(trend_anom, x='Mois', y='Nombre', color='type_anomalie',
                                              title="√âvolution Mensuelle du Nombre d'Anomalies par Type",
                                              markers=True, labels={'type_anomalie': 'Type d\'Anomalie'})
                         st.plotly_chart(fig_trend, use_container_width=True)
                         afficher_dataframe_avec_export(trend_anom, "Donn√©es Tendances Anomalies", key="kpi_trend_anom_data")
                     else:
                         st.info("Aucune anomalie trouv√©e pour les cat√©gories s√©lectionn√©es dans la p√©riode.")
                 else:
                     st.info("Aucune anomalie d√©tect√©e globalement dans la p√©riode.")


def afficher_page_autres_cartes(df_transactions: pd.DataFrame, df_autres: pd.DataFrame, date_debut: datetime.date, date_fin: datetime.date):
    """Affiche la page d'analyse des 'Autres Cartes'."""
    st.header(f"üí≥ Analyse Autres Cartes ({date_debut.strftime('%d/%m/%Y')} - {date_fin.strftime('%d/%m/%Y')})")

    if df_autres is None or df_autres.empty:
        st.info("Aucune 'Autre Carte' n'est d√©finie dans le fichier des cartes.")
        return

    with st.expander("Liste des Autres Cartes D√©finies"):
        afficher_dataframe_avec_export(df_autres, "Liste des Autres Cartes", key="autres_cartes_liste")

    cartes_autres_list = df_autres['N¬∞ Carte'].unique()
    data_autres = df_transactions[df_transactions['Card num.'].isin(cartes_autres_list)].copy()

    if data_autres.empty:
        st.warning("Aucune transaction trouv√©e pour les 'Autres Cartes' sur la p√©riode s√©lectionn√©e.")
        return

    st.subheader("Consommation et Co√ªt des Autres Cartes")
    # Essayer d'inclure le nom si disponible
    group_cols = ['Card num.']
    if 'Card name' in data_autres.columns:
        group_cols.append('Card name')

    conso_autres = data_autres.groupby(group_cols).agg(
        Volume_Total_L=('Quantity', 'sum'),
        Cout_Total_CFA=('Amount', 'sum'),
        Nb_Transactions=('Quantity', 'count'),
        Volume_Moyen_L=('Quantity', 'mean'),
        Cout_Moyen_CFA=('Amount', 'mean')
    ).reset_index().round(2)

    # S'assurer que Card name est pr√©sent m√™me si non utilis√© dans groupby
    if 'Card name' not in conso_autres.columns:
         # Fusionner pour r√©cup√©rer le nom si possible (peut cr√©er doublons si nom change)
         card_names = data_autres[['Card num.', 'Card name']].drop_duplicates()
         conso_autres = conso_autres.merge(card_names, on='Card num.', how='left')
         # Mettre 'N/A' si toujours manquant
         conso_autres['Card name'] = conso_autres['Card name'].fillna('N/A')


    afficher_dataframe_avec_export(conso_autres, "R√©sum√© par Autre Carte", key="autres_cartes_summary")

    st.subheader("√âvolution de la Consommation (Autres Cartes)")
    conso_temp_autres = data_autres.groupby(pd.Grouper(key='Date', freq='D'))['Quantity'].sum().reset_index()
    if not conso_temp_autres.empty:
        fig_autres_line = px.line(conso_temp_autres, x='Date', y='Quantity', title="Consommation Quotidienne (Volume) - Autres Cartes")
        st.plotly_chart(fig_autres_line, use_container_width=True)
    else:
        st.info("Pas assez de donn√©es pour afficher l'√©volution quotidienne.")


def afficher_page_parametres(df_vehicules: Optional[pd.DataFrame] = None):
    """Affiche la page des param√®tres modifiables."""
    st.header("‚öôÔ∏è Param√®tres de l'Application")
    st.warning("Modifier ces param√®tres affectera les analyses et la d√©tection d'anomalies.")

    with st.expander("Seuils G√©n√©raux d'Anomalies", expanded=True):
        st.session_state.ss_seuil_heures_rapprochees = st.number_input(
            "Seuil Prises Rapproch√©es (heures)",
            min_value=0.5, max_value=24.0,
            value=float(st.session_state.get('ss_seuil_heures_rapprochees', DEFAULT_SEUIL_HEURES_RAPPROCHEES)),
            step=0.5, format="%.1f", key='param_seuil_rappr'
        )
        st.session_state.ss_delta_minutes_facturation_double = st.number_input(
            "Delta Max Facturation Double (minutes)",
            min_value=1, max_value=180,
            value=st.session_state.get('ss_delta_minutes_facturation_double', DEFAULT_DELTA_MINUTES_FACTURATION_DOUBLE),
            step=1, key='param_delta_double'
        )
        st.session_state.ss_seuil_anomalies_suspectes_score = st.number_input(
            "Seuil Score de Risque Suspect",
            min_value=1, max_value=1000,
            value=st.session_state.get('ss_seuil_anomalies_suspectes_score', DEFAULT_SEUIL_ANOMALIES_SUSPECTES_SCORE),
            step=1, key='param_seuil_score'
        )

    with st.expander("Heures Non Ouvr√©es"):
        st.session_state.ss_heure_debut_non_ouvre = st.slider(
            "Heure D√©but P√©riode Non Ouvr√©e",
            min_value=0, max_value=23,
            value=st.session_state.get('ss_heure_debut_non_ouvre', DEFAULT_HEURE_DEBUT_NON_OUVRE),
            step=1, key='param_heure_debut_no'
        )
        st.session_state.ss_heure_fin_non_ouvre = st.slider(
            # Texte ajust√© : l'heure de fin est exclusive (ex: fin 6h => inclut 0h √† 5h59)
            "Heure Fin P√©riode Non Ouvr√©e (exclusive)",
             min_value=0, max_value=23,
            value=st.session_state.get('ss_heure_fin_non_ouvre', DEFAULT_HEURE_FIN_NON_OUVRE),
            step=1, key='param_heure_fin_no'
        )
        st.caption(f"Plage non ouvr√©e actuelle (approximative): de {st.session_state.ss_heure_debut_non_ouvre}h √† {st.session_state.ss_heure_fin_non_ouvre}h (hors weekend).")


    with st.expander("Seuils de Consommation par Cat√©gorie (L/100km)"):
        if df_vehicules is not None and st.session_state.get('data_loaded', False):
            # Utiliser les seuils stock√©s en session state
            current_seuils = st.session_state.get('ss_conso_seuils_par_categorie', {})
            all_cats = sorted(current_seuils.keys()) # Utiliser les cl√©s existantes

            new_seuils = {}
            cols = st.columns(3) # Afficher sur 3 colonnes
            col_idx = 0
            for cat in all_cats:
                with cols[col_idx % 3]:
                     new_seuils[cat] = st.number_input(
                         f"Seuil {cat}",
                         min_value=5.0, max_value=100.0,
                         value=float(current_seuils.get(cat, DEFAULT_CONSO_SEUIL)), # Utiliser la valeur actuelle
                         step=0.5, format="%.1f",
                         key=f"param_seuil_conso_{cat}"
                     )
                col_idx += 1
            # Mettre √† jour session state avec les nouvelles valeurs
            st.session_state.ss_conso_seuils_par_categorie = new_seuils
        else:
            st.info("Chargez les donn√©es pour d√©finir les seuils par cat√©gorie.")
            # Afficher le seuil par d√©faut si aucune donn√©e
            st.number_input("Seuil Consommation par D√©faut (utilis√© si cat√©gorie non d√©finie)", value=DEFAULT_CONSO_SEUIL, disabled=True)


    with st.expander("Poids des Anomalies pour Score de Risque"):
        st.caption("Ajustez l'importance de chaque type d'anomalie dans le calcul du score de risque.")
        c1, c2, c3 = st.columns(3)
        with c1:
            st.session_state.ss_poids_conso_excessive = st.slider("Poids: Conso. Excessive", 1, 15, st.session_state.get('ss_poids_conso_excessive', DEFAULT_POIDS_CONSO_EXCESSIVE), key='poids_cex')
            st.session_state.ss_poids_depassement_capacite = st.slider("Poids: D√©passement Capacit√©", 1, 15, st.session_state.get('ss_poids_depassement_capacite', DEFAULT_POIDS_DEPASSEMENT_CAPACITE), key='poids_dep')
            st.session_state.ss_poids_prises_rapprochees = st.slider("Poids: Prises Rapproch√©es", 1, 15, st.session_state.get('ss_poids_prises_rapprochees', DEFAULT_POIDS_PRISES_RAPPROCHEES), key='poids_rap')
        with c2:
            st.session_state.ss_poids_km_decroissant = st.slider("Poids: Km D√©croissant", 1, 15, st.session_state.get('ss_poids_km_decroissant', DEFAULT_POIDS_KM_DECROISSANT), key='poids_kmd')
            st.session_state.ss_poids_km_inchange = st.slider("Poids: Km Inchang√©", 1, 15, st.session_state.get('ss_poids_km_inchange', DEFAULT_POIDS_KM_INCHANGE), key='poids_kmi')
            st.session_state.ss_poids_km_saut = st.slider("Poids: Saut Km Important", 1, 15, st.session_state.get('ss_poids_km_saut', DEFAULT_POIDS_KM_SAUT), key='poids_kms')
        with c3:
            st.session_state.ss_poids_hors_horaire = st.slider("Poids: Hors Horaires/WE", 1, 15, st.session_state.get('ss_poids_hors_horaire', DEFAULT_POIDS_HORS_HORAIRE), key='poids_hor')
            st.session_state.ss_poids_hors_service = st.slider("Poids: V√©hicule Hors Service", 1, 15, st.session_state.get('ss_poids_hors_service', DEFAULT_POIDS_HORS_SERVICE), key='poids_hsv')
            st.session_state.ss_poids_fact_double = st.slider("Poids: Facturation Double", 1, 15, st.session_state.get('ss_poids_fact_double', DEFAULT_POIDS_FACT_DOUBLE), key='poids_dbl')

    st.markdown("---")
    st.info("Les param√®tres sont sauvegard√©s automatiquement pendant la session.")


# ---------------------------------------------------------------------
# Point d'entr√©e avec navigation mise √† jour
# ---------------------------------------------------------------------
def main():
    st.title("üìä Gestion & Analyse Cartes Carburant")

    # --- Chargement Fichiers ---
    st.sidebar.header("1. Chargement des Donn√©es")
    fichier_transactions = st.sidebar.file_uploader("Fichier Transactions (CSV)", type=['csv'])
    fichier_cartes = st.sidebar.file_uploader("Fichier Cartes (Excel)", type=['xlsx', 'xls'])

    if not fichier_transactions or not fichier_cartes:
        st.info("üëã Bienvenue ! Veuillez charger le fichier des transactions (CSV) et le fichier des cartes (Excel) via la barre lat√©rale pour commencer.")
        initialize_session_state() # Initialiser m√™me sans donn√©es pour afficher les param√®tres
        # Afficher la page des param√®tres m√™me sans donn√©es charg√©es
        if st.sidebar.radio("Navigation", ["Param√®tres"], index=0) == "Param√®tres":
            afficher_page_parametres()
        return

    # --- Chargement et Nettoyage ---
    df_transactions, df_vehicules, df_ge, df_autres = charger_donnees(fichier_transactions, fichier_cartes)

    # --- V√©rification Post-Chargement ---
    if df_transactions is None or df_vehicules is None or df_ge is None or df_autres is None:
        st.error("‚ùå Erreur lors du chargement ou de la validation des fichiers. Veuillez v√©rifier les fichiers et les colonnes requises.")
        st.session_state['data_loaded'] = False
        return # Arr√™ter si le chargement √©choue

    st.session_state['data_loaded'] = True
    st.sidebar.success("‚úÖ Donn√©es charg√©es avec succ√®s !")
    min_date, max_date = df_transactions['Date'].min(), df_transactions['Date'].max()
    st.sidebar.markdown(f"**Transactions :** {len(df_transactions):,}")
    st.sidebar.markdown(f"**P√©riode :** {min_date.strftime('%d/%m/%Y')} - {max_date.strftime('%d/%m/%Y')}")

    # --- Initialisation dynamique de session_state (apr√®s chargement) ---
    initialize_session_state(df_vehicules)

    # --- S√©lection P√©riode Globale (optionnel, peut √™tre par page) ---
    st.sidebar.header("2. P√©riode d'Analyse Globale")
    col_date1, col_date2 = st.sidebar.columns(2)
    global_date_debut = col_date1.date_input("Date D√©but", min_date.date(), min_value=min_date.date(), max_value=max_date.date(), key="global_date_debut")
    global_date_fin = col_date2.date_input("Date Fin", max_date.date(), min_value=min_date.date(), max_value=max_date.date(), key="global_date_fin")

    if global_date_debut > global_date_fin:
        st.sidebar.error("La date de d√©but ne peut pas √™tre post√©rieure √† la date de fin.")
        return

    # Filtrer les donn√©es principales une seule fois pour la p√©riode globale
    mask_global_date = (df_transactions['Date'].dt.date >= global_date_debut) & (df_transactions['Date'].dt.date <= global_date_fin)
    df_transac_filtered = df_transactions[mask_global_date].copy()

    if df_transac_filtered.empty:
         st.warning("Aucune transaction trouv√©e pour la p√©riode s√©lectionn√©e.")
         # Permettre la navigation m√™me sans donn√©es filtr√©es
    else:
         st.sidebar.info(f"{len(df_transac_filtered):,} transactions dans la p√©riode s√©lectionn√©e.")


    # --- Navigation avec la nouvelle page "Analyse par P√©riode" ---
    st.sidebar.header("3. Navigation")
    pages = [
        "Tableau de Bord", "Analyse V√©hicules", "Analyse des Co√ªts", 
        "Analyse par P√©riode", "Anomalies", "KPIs", "Autres Cartes", "Param√®tres"
    ]
    if not df_transac_filtered.empty:
         page = st.sidebar.radio("Choisir une page :", pages, key="navigation")
    else: # Si pas de donn√©es filtr√©es, limiter les pages accessibles
         page = st.sidebar.radio("Choisir une page :", ["Tableau de Bord", "Autres Cartes", "Param√®tres"], key="navigation_limited")


    # --- Contenu des Pages ---
    if page == "Tableau de Bord":
        # Recalculer les KPI ici pour avoir la conso moyenne cat√©gorie √† jour
        kpi_cat_dashboard, df_vehicle_kpi_dashboard = calculer_kpis_globaux(
            df_transac_filtered, df_vehicules, global_date_debut, global_date_fin,
            list(st.session_state.ss_conso_seuils_par_categorie.keys()) # Toutes cat√©gories
        )
        afficher_page_dashboard(df_transac_filtered, df_vehicules, df_ge, df_autres, global_date_debut, global_date_fin)
        # Ajouter l'am√©lioration du dashboard
        ameliorer_dashboard(df_transac_filtered, df_vehicules, global_date_debut, global_date_fin, 
                        kpi_cat_dashboard, df_vehicle_kpi_dashboard)
    elif page == "Analyse V√©hicules":
         # Recalculer les KPI ici pour avoir la conso moyenne cat√©gorie √† jour
         kpi_cat_dashboard, df_vehicle_kpi_dashboard = calculer_kpis_globaux(
             df_transac_filtered, df_vehicules, global_date_debut, global_date_fin,
             list(st.session_state.ss_conso_seuils_par_categorie.keys()) # Toutes cat√©gories
         )
         afficher_page_analyse_vehicules(df_transac_filtered, df_vehicules, global_date_debut, global_date_fin, kpi_cat_dashboard)
    elif page == "Analyse des Co√ªts":
         afficher_page_analyse_couts(df_transac_filtered, df_vehicules, global_date_debut, global_date_fin)
    elif page == "Analyse par P√©riode":
         afficher_page_analyse_periodes(df_transac_filtered, df_vehicules, global_date_debut, global_date_fin)
    elif page == "Anomalies":
        afficher_page_anomalies(df_transac_filtered, df_vehicules, global_date_debut, global_date_fin)
    elif page == "KPIs":
        afficher_page_kpi(df_transac_filtered, df_vehicules, global_date_debut, global_date_fin)
    elif page == "Autres Cartes":
        afficher_page_autres_cartes(df_transac_filtered, df_autres, global_date_debut, global_date_fin)
    elif page == "Param√®tres":
        afficher_page_parametres(df_vehicules) # Passer df_vehicules pour MAJ cat√©gories


# ---------------------------------------------------------------------
# Ex√©cution de l'application
# ---------------------------------------------------------------------
if __name__ == "__main__":
    main()
